{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c3d01a",
   "metadata": {},
   "source": [
    "# Inference into model performance\n",
    "\n",
    "The following code is used as a pipeline to analyse the models trained based on different metrics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff1f21",
   "metadata": {},
   "source": [
    "Load the necessary packages, data and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e632b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import joblib\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, average_precision_score,\n",
    "    precision_recall_fscore_support, balanced_accuracy_score, matthews_corrcoef,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import umap.umap_ as UMAP\n",
    "import os\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from tqdm import tqdm \n",
    "from scipy.stats import mannwhitneyu\n",
    "from PIL import Image\n",
    "\n",
    "# Custom functions\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "from datasets import *\n",
    "from CNN_AE_helper import *\n",
    "from CNN3d import *\n",
    "from vein_detection import *\n",
    "from visualization_helper import *\n",
    "from reconstruction_error import *\n",
    "from roc_percision_recall import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427104de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy: 321\n",
      "Early diseased: 12\n",
      "Mid diseased: 25\n",
      "Late diseased: 30\n"
     ]
    }
   ],
   "source": [
    "# FX10 camera\n",
    "IMG_DIR = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5'\n",
    "# IMG_DIR = '/home/u0158953/data/Strawberries/PotsprocessedData/cropped_hdf5'\n",
    "CAMERA = 'FX10'\n",
    "\n",
    "# Healthy leaves\n",
    "DATES = ['07SEPT2023', '08SEPT2023', '09SEPT2023', '10SEPT2023', '11SEPT2023', '12SEPT2023',\n",
    "         '13SEPT2023', '14SEPT2023', '15SEPT2023', '18SEPT2023', '19SEPT2023']\n",
    "TRAYS = ['3D', '4C', '4D', '2D']    # Some files from the FX17 camera are mistakenly named in 2D instead of 4D\n",
    "healthy_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Early diseased leaves\n",
    "DATES = ['07SEPT2023']\n",
    "TRAYS = ['3C']\n",
    "early_diseased_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Mid diseased leaves\n",
    "DATES = ['08SEPT2023', '09SEPT2023']\n",
    "TRAYS = ['3C']\n",
    "mid_diseased_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Late diseased leaves\n",
    "DATES = ['10SEPT2023', '11SEPT2023', '12SEPT2023', '13SEPT2023', '14SEPT2023', '15SEPT2023']\n",
    "TRAYS = ['3C']\n",
    "late_diseased_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Number of samples in each category\n",
    "print(f'Healthy: {len(healthy_FX10)}')\n",
    "print(f'Early diseased: {len(early_diseased_FX10)}')\n",
    "print(f'Mid diseased: {len(mid_diseased_FX10)}')\n",
    "print(f'Late diseased: {len(late_diseased_FX10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c094c71",
   "metadata": {},
   "source": [
    "**Split data into train, validation and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(healthy_FX10, test_size=0.20, random_state=10)\n",
    "train, validation = train_test_split(train, test_size=0.185, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da94a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Total number of GPUs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator PCA from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MASK_FOLDER = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_masks/'\n",
    "#MASK_FOLDER = \"/home/u0158953/data/Strawberries/PotsprocessedData/cropped_masks\"\n",
    "#MASK_FOLDER = '/home/r0979317/Documents/Thesis_Strawberries/Data/cropped_masks'\n",
    "BATCH_SIZE = 8\n",
    "MASK_METHOD = 1    # 0 for only leaf, 1 for leaf+stem\n",
    "BAND_SELECTION = [489.3, 505.1, 542.21, 550.2, 558.21, 582.31, 625.4, 660.62, 674.2, 679.64,\n",
    "                  701.44, 717.81, 736.94, 745.15, 783.52, 866.08, 951.83]    # Important wavelengths obtained from pca_bandselect.ipynb 819.25,\n",
    "POLYORDER = 2\n",
    "WINDOW_LENGTH = 4 \n",
    "PREPROCESS_METHOD = \"normal\"\n",
    "PATCH_PROBABILITY = 0.0 # amount of data the dataloader randomly zooms into\n",
    "#SCALER = joblib.load('/home/r0979317/Documents/Thesis_Strawberries/Thesis_code/master_thesis/models/pca/scaler_healthy.joblib')    \n",
    "#PCA = joblib.load('/home/r0979317/Documents/Thesis_Strawberries/Thesis_code/master_thesis/models/pca/pca_model_healthy.joblib')    \n",
    "SCALER = joblib.load('C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/GitLab/master_thesis/models/pca/scaler_healthy.joblib')\n",
    "PCA = joblib.load('C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/GitLab/master_thesis/models/pca/pca_model_healthy.joblib')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "print(f'Total number of GPUs: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0ebf6",
   "metadata": {},
   "source": [
    "**Data augmentations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f263499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentations\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((256, 256)),    # By default this uses bilinear interpolation which is good.\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=(0, 180), interpolation=v2.InterpolationMode.BILINEAR),\n",
    "])\n",
    "\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43caafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "#####################\n",
    "### TRAINING DATA ###\n",
    "#####################\n",
    "dataset_train_hsi = HsiDataset(train, MASK_FOLDER, transform=train_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               pca=None, scaler=None, polyorder=POLYORDER, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD, patch_probability = PATCH_PROBABILITY)\n",
    "dataloader_train_hsi = DataLoader(dataset_train_hsi, batch_size=BATCH_SIZE, shuffle=True, collate_fn=None)\n",
    "\n",
    "#######################\n",
    "### VALIDATION DATA ###\n",
    "#######################\n",
    "dataset_validation_hsi = HsiDataset(validation, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               pca=None, scaler=None, polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD, patch_probability = PATCH_PROBABILITY)\n",
    "dataloader_validation_hsi = DataLoader(dataset_validation_hsi, batch_size=BATCH_SIZE, shuffle=False, collate_fn=None)\n",
    "\n",
    "#################\n",
    "### TEST DATA ###\n",
    "#################\n",
    "dataset_test_hsi = HsiDataset(test, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               pca=None, scaler=None, polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD, patch_probability = PATCH_PROBABILITY)\n",
    "dataloader_test_hsi = DataLoader(dataset_test_hsi, batch_size=BATCH_SIZE, shuffle=False, collate_fn=None)\n",
    "\n",
    "###########################\n",
    "### EARLY DISEASED DATA ###\n",
    "###########################\n",
    "dataset_early_diseased_hsi = HsiDataset(early_diseased_FX10, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               pca=None, scaler=None, polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD, patch_probability = PATCH_PROBABILITY)\n",
    "dataloader_early_diseased_hsi = DataLoader(dataset_early_diseased_hsi, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "#########################\n",
    "### MID DISEASED DATA ###\n",
    "#########################\n",
    "dataset_mid_diseased_hsi = HsiDataset(mid_diseased_FX10, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION,\n",
    "                               pca=None, scaler=None, polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD, patch_probability = PATCH_PROBABILITY)\n",
    "dataloader_mid_diseased_hsi = DataLoader(dataset_mid_diseased_hsi, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "##########################\n",
    "### LATE DISEASED DATA ###\n",
    "##########################\n",
    "dataset_late_diseased_hsi = HsiDataset(late_diseased_FX10, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION,\n",
    "                               pca=None, scaler=None, polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD, patch_probability = PATCH_PROBABILITY)\n",
    "dataloader_late_diseased_hsi = DataLoader(dataset_late_diseased_hsi, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a366c2",
   "metadata": {},
   "source": [
    "# Load Model that needs to be investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceebc9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/GitLab/master_thesis/models/3D_autoencoder/first_normal_max_model.pth, Last Epoch: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\CNN_AE_helper.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=device)  # Ensures compatibility across devices\n"
     ]
    }
   ],
   "source": [
    "# --- Instantiate model ---\n",
    "model = CNN3DAEMAX_try(layers_list=[18, 18, 32, 32], input_dim=1, kernel_sizes=3, strides=(1, 2, 2), paddings=1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Load the checkpoint\n",
    "model, optimizer, train_losses, val_losses, last_epoch = load_checkpoint(model, 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/GitLab/master_thesis/models/3D_autoencoder/first_normal_max_model.pth', device, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d97476a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all plots in this directory\n",
    "model_name = \"max_normal_test\"\n",
    "save_path = f'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Images/{model_name}' \n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22519b9",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "As inference techniques we will conduct:\n",
    "\n",
    "Metrics without threshold\n",
    "- AUC\n",
    "- AUPRC\n",
    "- FPR@95%TPR\n",
    "\n",
    "Threshold based metrics\n",
    "- Max-value\n",
    "- 95-quantile\n",
    "- mean + 2*standard deviation\n",
    "- Max-Area?\n",
    "\n",
    "- The overall reconstruction error value\n",
    "- NO of 99% extreme reconstruction errors\n",
    "- NOP of 99% extreme reconstruction error per band\n",
    "- Vein area\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24f381",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a598695d",
   "metadata": {},
   "source": [
    "**!!!!!!! IF STACKED MODEL CHOSEN GO TO SECTION STACKED MODEL FOR INFERENCE!!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df658ae2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "609d4bf6",
   "metadata": {},
   "source": [
    "## ROC and Percision-Recall for binary evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814e5e5",
   "metadata": {},
   "source": [
    "### Overall reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = 'mae'\n",
    "ERROR_METRIC = \"image_mean\"\n",
    "MASK_AFTER = True\n",
    "REMOVE_EDGES = True\n",
    "SIZE = 256\n",
    "#compare_auc_across_stages(model, healthy_dataloader, diseased_dataloaders, stages_labels, device, thresholds = 0, error_metric = \"image_mean\", error_type='mse',\n",
    "                             #mask_after=False, remove_edges=False, mask_resize=256, MASK_FOLDER = \"No_folder\")\n",
    "auc_results = compare_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi,  # Using validation set as healthy reference\n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"],\n",
    "    device, \n",
    "    error_metric = ERROR_METRIC,\n",
    "    error_type=ERROR, \n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_AUC_ROC.png')\n",
    "\n",
    "pr_auc_results = compare_pr_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi, \n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"], \n",
    "    device, \n",
    "    error_metric = ERROR_METRIC, \n",
    "    error_type=ERROR,\n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_AUC_PR.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8153c0",
   "metadata": {},
   "source": [
    "**Reconstruction Error Visualization**\n",
    "\n",
    "First visualize errors per band and then overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_error_per_band(model, dataloader_train_hsi, device, save_path = f'{save_path}/reconstruction_error_per_band_train.png',\n",
    "                                        error_type='mae', vmax=0.2, minmax = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f64c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization with edges removed: visu_reconsruction_error would add edges\n",
    "visu_reconstruction_error_edge_removed(model, dataloader_validation_hsi, device, save_path = f'{save_path}/reconstruction_error_validation',\n",
    "                                       error_type='mae', vmax=0.2, minmax = False)\n",
    "visu_reconstruction_error_edge_removed(model, dataloader_test_hsi, device, save_path = f'{save_path}/reconstruction_error_test'\n",
    "                                       , error_type='mae', vmax=0.2, minmax = False)\n",
    "visu_reconstruction_error_edge_removed(model, dataloader_early_diseased_hsi, device, save_path = f'{save_path}/reconstruction_error_early', \n",
    "                                        error_type='mae', vmax=0.2, minmax = False)\n",
    "visu_reconstruction_error_edge_removed(model, dataloader_mid_diseased_hsi, device, save_path = f'{save_path}/reconstruction_error_mid', \n",
    "                                       error_type='mae', vmax=0.2, minmax = False)\n",
    "visu_reconstruction_error_edge_removed(model, dataloader_late_diseased_hsi, device, save_path = f'{save_path}/reconstruction_error_late', \n",
    "                                        error_type='mae', vmax=0.2, minmax = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4b8e1",
   "metadata": {},
   "source": [
    "## Alternative Errors\n",
    "\n",
    "1. Extreme pixel error rate per band\n",
    "2. Latent space error\n",
    "3. Disease specific error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403209e0",
   "metadata": {},
   "source": [
    "To get Extreme pixel error per band:\n",
    "\n",
    "-> calculate 99% quantile of validation dataset to get thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda46542",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_threshold_band_noedge = get_pixel_threshold_per_band_edge_removal(model, dataloader_validation_hsi, device, MASK_FOLDER, quantile=0.99, error_metric=\"MAE\")\n",
    "# print the thresholds\n",
    "print(pix_threshold_band_noedge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum: 0.06094030287116785, maximum: 0.17580827474594152, median: 0.08709860444068918, p25: 0.07988026991486558, p75: 0.15381613880395906\n",
      "[0.06137524 0.06311501 0.0639855  0.1699026  0.17530691 0.175708  ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate simple statistics about the thresholds for inside\n",
    "minimum       = np.min(pix_threshold_band_noedge)\n",
    "maximum       = np.max(pix_threshold_band_noedge)\n",
    "median        = np.percentile(pix_threshold_band_noedge, 50)       # 50th percentile\n",
    "p25, p75      = np.percentile(pix_threshold_band_noedge, [25, 75]) # 25th and 75th percentiles\n",
    "other_quants  = np.percentile(pix_threshold_band_noedge, [1, 5, 10, 90, 95, 99])\n",
    "\n",
    "print(f'minimum: {minimum}, maximum: {maximum}, median: {median}, p25: {p25}, p75: {p75}')\n",
    "print(other_quants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16366969",
   "metadata": {},
   "source": [
    "### Extreme pixel error rate per band "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2546dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = 'mae'\n",
    "ERROR_METRIC = \"extreme_bands_99\"\n",
    "MASK_AFTER = True\n",
    "REMOVE_EDGES = True\n",
    "SIZE = 256\n",
    "#compare_auc_across_stages(model, healthy_dataloader, diseased_dataloaders, stages_labels, device, thresholds = 0, error_metric = \"image_mean\", error_type='mse',\n",
    "                             #mask_after=False, remove_edges=False, mask_resize=256, MASK_FOLDER = \"No_folder\")\n",
    "auc_results = compare_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi,  # Using validation set as healthy reference\n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"],\n",
    "    device, \n",
    "    threshold_band=pix_threshold_band_noedge,\n",
    "    error_metric = ERROR_METRIC,\n",
    "    error_type=ERROR, \n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_AUC_ROC.png')\n",
    "\n",
    "pr_auc_results = compare_pr_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi, \n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"], \n",
    "    device,  \n",
    "    threshold_band=pix_threshold_band_noedge,\n",
    "    error_metric = ERROR_METRIC, \n",
    "    error_type=ERROR,\n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER,\n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_AUC_PR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e76515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to conduct the statistical analysis on a band level\n",
    "def stats_threshold_exceedance_dataset(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    thresholds,\n",
    "    MASK_FOLDER,\n",
    "    bands_to_show=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For each band, compute for *each* image in dataloader the % of valid (non-edge)\n",
    "    pixels whose abs-reconstruction-error exceeds thresholds[b].\n",
    "    Returns a dict mapping band -> {\n",
    "        'mean': float,\n",
    "        'min': float,\n",
    "        'max': float,\n",
    "        'all_percs': np.ndarray of shape (N_images,)\n",
    "    }\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    C = None\n",
    "\n",
    "    # initialize a list of lists to collect percentages, one inner list per band\n",
    "    per_band_percs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, idxs in tqdm(dataloader, desc=\"Computing stats\"):\n",
    "            # imgs: [B, C, H, W]\n",
    "            imgs = imgs.to(device)\n",
    "            recons = model(imgs.unsqueeze(1)).squeeze(1)  # [B, C, H, W]\n",
    "\n",
    "            B, C, H, W = imgs.shape\n",
    "            if per_band_percs == []:\n",
    "                if bands_to_show is None:\n",
    "                    bands_to_show = list(range(C))\n",
    "                per_band_percs = [[] for _ in bands_to_show]\n",
    "\n",
    "            for bi in range(B):\n",
    "                data_np  = imgs[bi].cpu().numpy()      # [C, H, W]\n",
    "                recon_np = recons[bi].cpu().numpy()    # [C, H, W]\n",
    "                idx_img  = idxs[bi].item()\n",
    "\n",
    "                # load + resize mask & compute valid_mask\n",
    "                mask_path = os.path.join(\n",
    "                    MASK_FOLDER,\n",
    "                    os.path.basename(dataloader.dataset.img_paths[idx_img])\n",
    "                        .replace('.hdf5','.png')\n",
    "                )\n",
    "                mask = Image.open(mask_path).convert('L')\n",
    "                mask = mask.resize((W, H), resample=Image.NEAREST)\n",
    "                mask = np.array(mask)\n",
    "                edge = extract_full_edge(mask)\n",
    "                valid = (1 - edge).astype(bool)        \n",
    "\n",
    "                # for each band, compute % exceedance\n",
    "                for ib, b in enumerate(bands_to_show):\n",
    "                    err = np.abs(data_np[b] - recon_np[b])\n",
    "                    valid_err = err[valid]\n",
    "                    if valid_err.size == 0:\n",
    "                        perc = 0.0\n",
    "                    else:\n",
    "                        exceed = (valid_err > thresholds[b]).sum()\n",
    "                        perc = 100.0 * exceed / valid_err.size\n",
    "\n",
    "                    per_band_percs[ib].append(perc)\n",
    "\n",
    "    results = {}\n",
    "    for ib, b in enumerate(bands_to_show):\n",
    "        arr = np.array(per_band_percs[ib])\n",
    "        results[b] = {\n",
    "            'mean': float(arr.mean()),\n",
    "            'min':  float(arr.min()),\n",
    "            'max':  float(arr.max()),\n",
    "            'all_percs': arr\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52194b",
   "metadata": {},
   "source": [
    "**Compute Mann-Whitney U test**\n",
    "\n",
    "Shows in which band the distribution of the extreme error rate is signficantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = list(range(17)) # for SNV model choose 210 here\n",
    "print(bands)\n",
    "\n",
    "# \n",
    "stats_healthy = stats_threshold_exceedance_dataset(\n",
    "    model=model,\n",
    "    dataloader=dataloader_test_hsi,\n",
    "    device=device,\n",
    "    thresholds=pix_threshold_band_noedge,           \n",
    "    MASK_FOLDER=MASK_FOLDER,\n",
    "    bands_to_show=bands     # or None for all bands\n",
    ")\n",
    "\n",
    "stats_early = stats_threshold_exceedance_dataset(\n",
    "    model=model,\n",
    "    dataloader=dataloader_early_diseased_hsi,\n",
    "    device=device,\n",
    "    thresholds=pix_threshold_band_noedge,          \n",
    "    MASK_FOLDER=MASK_FOLDER,\n",
    "    bands_to_show=bands     # or None for all bands\n",
    ")\n",
    "\n",
    "stats_mid = stats_threshold_exceedance_dataset(\n",
    "    model=model,\n",
    "    dataloader=dataloader_mid_diseased_hsi,\n",
    "    device=device,\n",
    "    thresholds=pix_threshold_band_noedge,           \n",
    "    MASK_FOLDER=MASK_FOLDER,\n",
    "    bands_to_show=bands   # or None for all bands\n",
    ")\n",
    "\n",
    "stats_late = stats_threshold_exceedance_dataset(\n",
    "    model=model,\n",
    "    dataloader=dataloader_late_diseased_hsi,\n",
    "    device=device,\n",
    "    thresholds=pix_threshold_band_noedge,           \n",
    "    MASK_FOLDER=MASK_FOLDER,\n",
    "    bands_to_show=bands     # or None for all bands\n",
    ")\n",
    "\n",
    "\n",
    "# apply the Mann-Whitney U test to see if the error rates are significantly different distributed\n",
    "records = []\n",
    "labels = [\"healthy\", \"early\", \"mid\", \"late\"]\n",
    "dicts = [stats_healthy, stats_early, stats_mid, stats_late]\n",
    "\n",
    "for band in range(17):\n",
    "    grp_healthy = stats_healthy[band]['all_percs']\n",
    "    for label, stats_dict in zip(labels[1:], dicts[1:]):\n",
    "        grp_sub = stats_dict[band]['all_percs']\n",
    "        stat, p = mannwhitneyu(grp_healthy, grp_sub, alternative='two-sided')\n",
    "        p_corr = min(p * 3, 1.0)  # Bonferroni correction for 3 comparisons\n",
    "        records.append({\n",
    "            'Band': band,\n",
    "            'Comparison': f\"healthy vs {label}\",\n",
    "            'U': stat,\n",
    "            'p-value (Bonf)': p_corr\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records).set_index(['Band', 'Comparison'])\n",
    "\n",
    "\n",
    "# Get only the bands that are significant\n",
    "significant = df[df[\"p-value (Bonf)\"]<0.05]\n",
    "print(significant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe41f7f",
   "metadata": {},
   "source": [
    "**Visualize Errors above the 99% quantile**\n",
    "\n",
    "Pixels exceeding the 99% quantiel of a band are shown in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    for i in range(17):\n",
    "        visualize_threshold_exceedance_edge_removal(\n",
    "            model=model,\n",
    "            dataloader=dataloader_test_hsi,\n",
    "            device=device,\n",
    "            thresholds=pix_threshold_band_noedge,\n",
    "            save_path=f'{save_path}/pixel_exceeding_threshold_healthy_image{j}_band{i}.png',\n",
    "            MASK_FOLDER=MASK_FOLDER,\n",
    "            # optional:\n",
    "            band_colors={i: [1,0,0] for i in range(17)},  # all red overlays\n",
    "            select_img=j,         # first image in the batch\n",
    "            bands_to_show=[i] # only visualize bands 0,1,2\n",
    "        )\n",
    "\n",
    "for j in range(3):\n",
    "    for i in range(17):\n",
    "        visualize_threshold_exceedance_edge_removal(\n",
    "            model=model,\n",
    "            dataloader=dataloader_early_diseased_hsi,\n",
    "            device=device,\n",
    "            thresholds=pix_threshold_band_noedge,\n",
    "            save_path=f'{save_path}/pixel_exceeding_threshold_early_image{j}_band{i}.png',\n",
    "            MASK_FOLDER=MASK_FOLDER,\n",
    "            # optional:\n",
    "            band_colors={i: [1,0,0] for i in range(17)},  # all red overlays\n",
    "            select_img=j,         # first image in the batch\n",
    "            bands_to_show=[i] # only visualize bands 0,1,2\n",
    "        )\n",
    "\n",
    "for j in range(3):\n",
    "    for i in range(17):\n",
    "        visualize_threshold_exceedance_edge_removal(\n",
    "            model=model,\n",
    "            dataloader=dataloader_mid_diseased_hsi,\n",
    "            device=device,\n",
    "            thresholds=pix_threshold_band_noedge,\n",
    "            save_path=f'{save_path}/pixel_exceeding_threshold_mid_image{j}_band{i}.png',\n",
    "            MASK_FOLDER=MASK_FOLDER,\n",
    "            # optional:\n",
    "            band_colors={i: [1,0,0] for i in range(17)},  # all red overlays\n",
    "            select_img=j,         # first image in the batch\n",
    "            bands_to_show=[i] # only visualize bands 0,1,2\n",
    "        )\n",
    "\n",
    "for j in range(3):\n",
    "    for i in range(17):\n",
    "        visualize_threshold_exceedance_edge_removal(\n",
    "            model=model,\n",
    "            dataloader=dataloader_late_diseased_hsi,\n",
    "            device=device,\n",
    "            thresholds=pix_threshold_band_noedge,\n",
    "            save_path=f'{save_path}/pixel_exceeding_threshold_late_image{j}_band{i}.png',\n",
    "            MASK_FOLDER=MASK_FOLDER,\n",
    "            # optional:\n",
    "            band_colors={i: [1,0,0] for i in range(17)},  # all red overlays\n",
    "            select_img=j,         # first image in the batch\n",
    "            bands_to_show=[i] # only visualize bands 0,1,2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f51b0",
   "metadata": {},
   "source": [
    "### Latent space error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = 'mae'\n",
    "ERROR_METRIC = \"latent\"\n",
    "MASK_AFTER = True\n",
    "REMOVE_EDGES = True\n",
    "SIZE = 256\n",
    "#compare_auc_across_stages(model, healthy_dataloader, diseased_dataloaders, stages_labels, device, thresholds = 0, error_metric = \"image_mean\", error_type='mse',\n",
    "                             #mask_after=False, remove_edges=False, mask_resize=256, MASK_FOLDER = \"No_folder\")\n",
    "auc_results = compare_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi,  # Using validation set as healthy reference\n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"],\n",
    "    device, \n",
    "    error_metric = ERROR_METRIC,\n",
    "    error_type=ERROR, \n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_benfenati_AUC_ROC.png')\n",
    "\n",
    "pr_auc_results = compare_pr_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi, \n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"], \n",
    "    device, \n",
    "    error_metric = ERROR_METRIC, \n",
    "    error_type=ERROR,\n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_benfenati_AUC_PR.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f0600",
   "metadata": {},
   "source": [
    "### Disease-specific error metric (Vein errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = 'mae'\n",
    "ERROR_METRIC = \"veins\"\n",
    "MASK_AFTER = True\n",
    "REMOVE_EDGES = True\n",
    "SIZE = 256\n",
    "#compare_auc_across_stages(model, healthy_dataloader, diseased_dataloaders, stages_labels, device, thresholds = 0, error_metric = \"image_mean\", error_type='mse',\n",
    "                             #mask_after=False, remove_edges=False, mask_resize=256, MASK_FOLDER = \"No_folder\")\n",
    "auc_results = compare_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi,  # Using validation set as healthy reference\n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"],\n",
    "    device, \n",
    "    error_metric = ERROR_METRIC,\n",
    "    error_type=ERROR, \n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_AUC_ROC.png')\n",
    "\n",
    "pr_auc_results = compare_pr_auc_across_stages(\n",
    "    model,\n",
    "    dataloader_test_hsi, \n",
    "    [dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi],\n",
    "    [\"Early\", \"Mid\", \"Late\"], \n",
    "    device, \n",
    "    error_metric = ERROR_METRIC, \n",
    "    error_type=ERROR,\n",
    "    mask_after=MASK_AFTER, \n",
    "    remove_edges=REMOVE_EDGES, \n",
    "    mask_resize=SIZE,\n",
    "    MASK_FOLDER=MASK_FOLDER, \n",
    "    save_path = f'{save_path}/{ERROR_METRIC}_AUC_PR.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f516d",
   "metadata": {},
   "source": [
    "**Visualizations**\n",
    "\n",
    "First visualize vein detection, then the errors in the veins.\n",
    "\n",
    "Taken from vein_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697179df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vein detection\n",
    "vein_detection(dataloader_validation_hsi, device, MASK_FOLDER, save_path = f'{save_path}/veins_validation_' , plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = 0\n",
    "label_disease = 1\n",
    "visu_vein_error(model, dataloader_validation_hsi, label_test, device, MASK_FOLDER, save_path = f'{save_path}/vein_errors_validation_' , plot=True)\n",
    "visu_vein_error(model, dataloader_test_hsi, label_test, device, MASK_FOLDER, save_path = f'{save_path}/vein_errors_healthy_' , plot=True)\n",
    "visu_vein_error(model, dataloader_early_diseased_hsi, label_disease, device, MASK_FOLDER, save_path = f'{save_path}/vein_errors_early_' , plot=True)\n",
    "visu_vein_error(model, dataloader_mid_diseased_hsi, label_disease, device, MASK_FOLDER, save_path = f'{save_path}/vein_errors_mid_' , plot=True)\n",
    "visu_vein_error(model, dataloader_late_diseased_hsi, label_disease, device, MASK_FOLDER, save_path = f'{save_path}/vein_errors_late_' , plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c65c07",
   "metadata": {},
   "source": [
    "**Shows training and validation loss of model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879879e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, 166, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab3abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d9bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d988f452",
   "metadata": {},
   "source": [
    "## Stacked Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure required imports\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Define parameters\n",
    "ERROR = 'mae'                # 'mae' or 'mse'\n",
    "ERROR_METRIC = 'image_mean'  # 'image_mean', 'extreme_bands_99', 'latent', or 'veins'\n",
    "MASK_FOLDER = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_masks/'\n",
    "SAVE_DIR = save_path         # ensure this path exists\n",
    "\n",
    "    # Compare ROC AUC (stacked inputs)\n",
    "auc_results = compare_stacked_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=None,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_ROC.png'\n",
    "    )\n",
    "print(\"ROC AUC results:\", auc_results)\n",
    "\n",
    "    # Compare PR AUC (stacked inputs)\n",
    "pr_auc_results = compare_stacked_pr_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=None,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_PR.png'\n",
    "    )\n",
    "print(\"PR AUC results:\", pr_auc_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11930e61",
   "metadata": {},
   "source": [
    "**!!!! EXTREME BANDS RUNS OUT OF MEMORY EASILY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5726528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters\n",
    "ERROR = 'mae'                # 'mae' or 'mse'\n",
    "ERROR_METRIC = 'extreme_bands_99'  # 'image_mean', 'extreme_bands_99', 'latent', or 'veins'\n",
    "MASK_FOLDER = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_masks/'\n",
    "SAVE_DIR = save_path         # ensure this path exists\n",
    "\n",
    "\n",
    "thresholds = get_stacked_error_thresholds(model, dataloader_validation_hsi, device, MASK_FOLDER)\n",
    "\n",
    "    # Compare ROC AUC (stacked inputs)\n",
    "auc_results = compare_stacked_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=thresholds,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_ROC.png'\n",
    "    )\n",
    "print(\"ROC AUC results:\", auc_results)\n",
    "\n",
    "    # Compare PR AUC (stacked inputs)\n",
    "pr_auc_results = compare_stacked_pr_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=thresholds,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_PR.png'\n",
    "    )\n",
    "print(\"PR AUC results:\", pr_auc_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ddf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "ERROR = 'mae'                # 'mae' or 'mse'\n",
    "ERROR_METRIC = 'latent'  # 'image_mean', 'extreme_bands_99', 'latent', or 'veins'\n",
    "MASK_FOLDER = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_masks/'\n",
    "SAVE_DIR = save_path         # ensure this path exists\n",
    "\n",
    "    # Compare ROC AUC (stacked inputs)\n",
    "auc_results = compare_stacked_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=None,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_ROC.png'\n",
    "    )\n",
    "print(\"ROC AUC results:\", auc_results)\n",
    "\n",
    "    # Compare PR AUC (stacked inputs)\n",
    "pr_auc_results = compare_stacked_pr_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=None,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_PR.png'\n",
    "    )\n",
    "print(\"PR AUC results:\", pr_auc_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "ERROR = 'mae'                # 'mae' or 'mse'\n",
    "ERROR_METRIC = 'veins'  # 'image_mean', 'extreme_bands_99', 'latent', or 'veins'\n",
    "MASK_FOLDER = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_masks/'\n",
    "SAVE_DIR = save_path         # ensure this path exists\n",
    "\n",
    "    # Compare ROC AUC (stacked inputs)\n",
    "auc_results = compare_stacked_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=None,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_ROC.png'\n",
    "    )\n",
    "print(\"ROC AUC results:\", auc_results)\n",
    "\n",
    "    # Compare PR AUC (stacked inputs)\n",
    "pr_auc_results = compare_stacked_pr_auc_across_stages(\n",
    "        model=model,\n",
    "        healthy_dataloader=dataloader_test_hsi,\n",
    "        diseased_dataloaders=[\n",
    "            dataloader_early_diseased_hsi,\n",
    "            dataloader_mid_diseased_hsi,\n",
    "            dataloader_late_diseased_hsi\n",
    "        ],\n",
    "        stages_labels=[\"Early\", \"Mid\", \"Late\"],\n",
    "        device=device,\n",
    "        thresholds=None,\n",
    "        error_metric=ERROR_METRIC,\n",
    "        error_type=ERROR,\n",
    "        MASK_FOLDER=MASK_FOLDER,\n",
    "        save_path=f'{SAVE_DIR}/{ERROR_METRIC}_AUC_PR.png'\n",
    "    )\n",
    "print(\"PR AUC results:\", pr_auc_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2ade9",
   "metadata": {},
   "source": [
    "# MAX threshold\n",
    "\n",
    "The following shows seperation results if the max validation value is chosen as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image wise aggregated reconstruction error\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed_all(10)\n",
    "threshold_max = get_recon_error_threshold(model, dataloader_test_hsi, dataloader_early=dataloader_early_diseased_hsi,\n",
    "                                      dataloader_mid=dataloader_mid_diseased_hsi, dataloader_late=dataloader_late_diseased_hsi, device=device, file_path = save_path)\n",
    "print(threshold_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f269de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = 'mae'\n",
    "MASK_AFTER = False\n",
    "REMOVE_EDGES = True   \n",
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da73c8f",
   "metadata": {},
   "source": [
    "## Outdated Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab4da0",
   "metadata": {},
   "source": [
    "**FURTHER VISUALIZATIONS NOT SHOWN IN THE THESIS FOR PERSONAL DATA EXPLORATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"/home/r0979317/Documents/Thesis_Strawberries/models/third_fc_model.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "device = next(model.parameters()).device\n",
    "print(\"Model loaded and on device:\", device)\n",
    "\n",
    "datasets = {\n",
    "    \"Healthy\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "\n",
    "# Plot\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_pixel_reconstruction_errors(model, loader, device)\n",
    "\n",
    "    # Optional: clip 99th percentile for visualization\n",
    "    upper = np.percentile(errors, 99)\n",
    "\n",
    "    # histogram\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(errors, bins=100, range=(0, upper), color='skyblue', edgecolor='black', density=True)\n",
    "    plt.title(f\"Reconstruction Error Distribution - {name}\")\n",
    "    plt.xlabel(\"Pixelwise Reconstruction Error\")\n",
    "    plt.ylabel(\"Frequency (normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}pixelwise_bar_{name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f31a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Healthy\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "# Step 1: Collect all errors\n",
    "all_errors = {}\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_pixel_reconstruction_errors(model, loader, device)\n",
    "    all_errors[name] = errors\n",
    "\n",
    "lower_percentile = 5\n",
    "upper_percentile = 95\n",
    "\n",
    "# First, determine global lower and upper clipping bounds\n",
    "clip_lower = min(np.percentile(errors, lower_percentile) for errors in all_errors.values())\n",
    "clip_upper = max(np.percentile(errors, upper_percentile) for errors in all_errors.values())\n",
    "\n",
    "error_data = []\n",
    "labels = []\n",
    "\n",
    "for name, errors in all_errors.items():\n",
    "    # Keep only values between clip_lower and clip_upper\n",
    "    errors_clipped = errors[(errors >= clip_lower) & (errors <= clip_upper)]\n",
    "    error_data.append(errors_clipped)\n",
    "    labels.append(name)\n",
    "\n",
    "# Step 3: Plot violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.violinplot(error_data, showmeans=True, showmedians=True)\n",
    "plt.xticks(ticks=np.arange(1, len(labels) + 1), labels=labels, rotation=30)\n",
    "plt.title(\"Pixelwise Reconstruction Error Distribution\")\n",
    "plt.ylabel(\"Pixelwise Reconstruction Error\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_path}pixelwise_violin_quantile_{lower_percentile}_{upper_percentile}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71636369",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Healthy\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "# Step 1: Collect all errors\n",
    "all_errors = {}\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_pixel_reconstruction_errors(model, loader, device)\n",
    "    all_errors[name] = errors\n",
    "\n",
    "lower_percentile = 95\n",
    "upper_percentile = 100\n",
    "\n",
    "# First, determine global lower and upper clipping bounds\n",
    "clip_lower = min(np.percentile(errors, lower_percentile) for errors in all_errors.values())\n",
    "clip_upper = max(np.percentile(errors, upper_percentile) for errors in all_errors.values())\n",
    "\n",
    "error_data = []\n",
    "labels = []\n",
    "\n",
    "for name, errors in all_errors.items():\n",
    "    # Keep only values between clip_lower and clip_upper\n",
    "    errors_clipped = errors[(errors >= clip_lower) & (errors <= clip_upper)]\n",
    "    error_data.append(errors_clipped)\n",
    "    labels.append(name)\n",
    "\n",
    "# Step 3: Plot violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.violinplot(error_data, showmeans=True, showmedians=True)\n",
    "plt.xticks(ticks=np.arange(1, len(labels) + 1), labels=labels, rotation=30)\n",
    "plt.title(\"Pixelwise Reconstruction Error Distribution\")\n",
    "plt.ylabel(\"Pixelwise Reconstruction Error\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_path}pixelwise_violin_quantile_{lower_percentile}_{upper_percentile}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28134bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = get_pixel_threshold_per_band(model, dataloader_early_diseased_hsi, device, quantile=0.75)\n",
    "scores = classify_leaves_per_band(model, dataloader_early_diseased_hsi, device, thresholds)\n",
    "\n",
    "# Transpose for plotting (bands × images)\n",
    "scores_by_band = list(zip(*scores))  # list of 17 lists\n",
    "# Classify and gather scores per group\n",
    "all_scores_per_band = []  # will be list of [n_groups x n_images x bands]\n",
    "for dataloader in dataloader_list:\n",
    "    scores = classify_leaves_per_band(model, dataloader, device, thresholds)\n",
    "    all_scores_per_band.append(scores)\n",
    "\n",
    "# Transpose: bands x groups x images\n",
    "n_bands = len(thresholds)\n",
    "for band_idx in range(n_bands):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    for group_idx, group_scores in enumerate(all_scores_per_band):\n",
    "        # Extract scores for this band across all images in the group\n",
    "        band_scores = [img_scores[band_idx] for img_scores in group_scores]\n",
    "        plt.scatter(\n",
    "            [group_labels[group_idx]] * len(band_scores),\n",
    "            band_scores,\n",
    "            label=group_labels[group_idx],\n",
    "            color=colors[group_idx],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "\n",
    "    #plt.axhline(y=thresholds[band_idx], color='red', linestyle='--', label=f'Threshold ({thresholds[band_idx]:.2f})')\n",
    "    plt.title(f\"Band {band_idx+1} - Per-image Error Scores by Group\")\n",
    "    plt.ylabel(\"Aggregated Error (Above Threshold)\")\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}pixelwise_perimage_band{band_idx+1}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098323f9",
   "metadata": {},
   "source": [
    "### Pixelwise reconstruction error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac21e9",
   "metadata": {},
   "source": [
    "#### Plot the pixel-wise error per data group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95137669",
   "metadata": {},
   "source": [
    "Plot the pixelwise error and its frequency in  a certain group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df315216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"/home/r0979317/Documents/Thesis_Strawberries/models/third_fc_model.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "device = next(model.parameters()).device\n",
    "print(\"Model loaded and on device:\", device)\n",
    "\n",
    "datasets = {\n",
    "    \"Healthy\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "\n",
    "# Plot\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_pixel_reconstruction_errors(model, loader, device)\n",
    "\n",
    "    # Optional: clip 99th percentile for visualization\n",
    "    upper = np.percentile(errors, 99)\n",
    "\n",
    "    # histogram\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(errors, bins=100, range=(0, upper), color='skyblue', edgecolor='black', density=True)\n",
    "    plt.title(f\"Reconstruction Error Distribution - {name}\")\n",
    "    plt.xlabel(\"Pixelwise Reconstruction Error\")\n",
    "    plt.ylabel(\"Frequency (normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}pixelwise_bar_{name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35daacf",
   "metadata": {},
   "source": [
    "Plot the same data as a Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20714dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Healthy\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "# Step 1: Collect all errors\n",
    "all_errors = {}\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_pixel_reconstruction_errors(model, loader, device)\n",
    "    all_errors[name] = errors\n",
    "\n",
    "lower_percentile = 5\n",
    "upper_percentile = 95\n",
    "\n",
    "# First, determine global lower and upper clipping bounds\n",
    "clip_lower = min(np.percentile(errors, lower_percentile) for errors in all_errors.values())\n",
    "clip_upper = max(np.percentile(errors, upper_percentile) for errors in all_errors.values())\n",
    "\n",
    "error_data = []\n",
    "labels = []\n",
    "\n",
    "for name, errors in all_errors.items():\n",
    "    # Keep only values between clip_lower and clip_upper\n",
    "    errors_clipped = errors[(errors >= clip_lower) & (errors <= clip_upper)]\n",
    "    error_data.append(errors_clipped)\n",
    "    labels.append(name)\n",
    "\n",
    "# Step 3: Plot violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.violinplot(error_data, showmeans=True, showmedians=True)\n",
    "plt.xticks(ticks=np.arange(1, len(labels) + 1), labels=labels, rotation=30)\n",
    "plt.title(\"Pixelwise Reconstruction Error Distribution\")\n",
    "plt.ylabel(\"Pixelwise Reconstruction Error\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_path}pixelwise_violin_quantile_{lower_percentile}_{upper_percentile}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc75da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Healthy\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "# Step 1: Collect all errors\n",
    "all_errors = {}\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_pixel_reconstruction_errors(model, loader, device)\n",
    "    all_errors[name] = errors\n",
    "\n",
    "lower_percentile = 95\n",
    "upper_percentile = 100\n",
    "\n",
    "# First, determine global lower and upper clipping bounds\n",
    "clip_lower = min(np.percentile(errors, lower_percentile) for errors in all_errors.values())\n",
    "clip_upper = max(np.percentile(errors, upper_percentile) for errors in all_errors.values())\n",
    "\n",
    "error_data = []\n",
    "labels = []\n",
    "\n",
    "for name, errors in all_errors.items():\n",
    "    # Keep only values between clip_lower and clip_upper\n",
    "    errors_clipped = errors[(errors >= clip_lower) & (errors <= clip_upper)]\n",
    "    error_data.append(errors_clipped)\n",
    "    labels.append(name)\n",
    "\n",
    "# Step 3: Plot violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.violinplot(error_data, showmeans=True, showmedians=True)\n",
    "plt.xticks(ticks=np.arange(1, len(labels) + 1), labels=labels, rotation=30)\n",
    "plt.title(\"Pixelwise Reconstruction Error Distribution\")\n",
    "plt.ylabel(\"Pixelwise Reconstruction Error\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_path}pixelwise_violin_quantile_{lower_percentile}_{upper_percentile}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d9008",
   "metadata": {},
   "source": [
    "#### Pixel error classification and visualization per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08277f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_error = get_pixel_error_threshold(model, dataloader_test_hsi, device, quantile = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea6eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_early = classify_leaves_pixel_error_aggregate(model, dataloader_early_diseased_hsi, device, pix_error)\n",
    "# classify_leaves_pixel_error_mean classifies based on the mean error per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data groups to be considered. If change, change colors and labels as well\n",
    "dataloader_list = [dataloader_test_hsi, dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [] \n",
    "for i in dataloader_list:\n",
    "    errors.append(classify_leaves_pixel_error_mean(model, i, device, pix_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors and labels of the groups\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "group_labels = ['Healthy', 'Early Diseased','Mid Diseased', 'Severely Diseased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall aggregated error  \n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (scores, color, label) in enumerate(zip(errors, colors, group_labels)):\n",
    "    x = [i] * len(scores)\n",
    "    plt.scatter(x, scores, color=color, label=label, alpha=0.7)\n",
    "\n",
    "plt.xticks(ticks=range(len(group_labels)), labels=group_labels)\n",
    "plt.axhline(y=pix_error, color='red', linestyle='--', label=f'Threshold ({pix_error:.2f})')\n",
    "plt.ylabel(\"Aggregated Error (Above Threshold)\")\n",
    "plt.title(\"Per-image Error Scores by Group\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{save_path}pixelwise_image.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e594ac",
   "metadata": {},
   "source": [
    "#### Pixel error classification and visualization per image and band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5751708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = get_pixel_threshold_per_band(model, dataloader_early_diseased_hsi, device, quantile=0.75)\n",
    "scores = classify_leaves_per_band(model, dataloader_early_diseased_hsi, device, thresholds)\n",
    "\n",
    "# Transpose for plotting (bands × images)\n",
    "scores_by_band = list(zip(*scores))  # list of 17 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = get_pixel_threshold_per_band(model, dataloader_early_diseased_hsi, device, quantile=0.75)\n",
    "scores = classify_leaves_per_band(model, dataloader_early_diseased_hsi, device, thresholds)\n",
    "\n",
    "# Transpose for plotting (bands × images)\n",
    "scores_by_band = list(zip(*scores))  # list of 17 lists\n",
    "# Classify and gather scores per group\n",
    "all_scores_per_band = []  # will be list of [n_groups x n_images x bands]\n",
    "for dataloader in dataloader_list:\n",
    "    scores = classify_leaves_per_band(model, dataloader, device, thresholds)\n",
    "    all_scores_per_band.append(scores)\n",
    "\n",
    "# Transpose: bands x groups x images\n",
    "n_bands = len(thresholds)\n",
    "for band_idx in range(n_bands):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    for group_idx, group_scores in enumerate(all_scores_per_band):\n",
    "        # Extract scores for this band across all images in the group\n",
    "        band_scores = [img_scores[band_idx] for img_scores in group_scores]\n",
    "        plt.scatter(\n",
    "            [group_labels[group_idx]] * len(band_scores),\n",
    "            band_scores,\n",
    "            label=group_labels[group_idx],\n",
    "            color=colors[group_idx],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "\n",
    "    #plt.axhline(y=thresholds[band_idx], color='red', linestyle='--', label=f'Threshold ({thresholds[band_idx]:.2f})')\n",
    "    plt.title(f\"Band {band_idx+1} - Per-image Error Scores by Group\")\n",
    "    plt.ylabel(\"Aggregated Error (Above Threshold)\")\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}pixelwise_perimage_band{band_idx+1}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1227c84b",
   "metadata": {},
   "source": [
    "**COMPUTES VIOLIN PLOT PER BAND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_errors_per_band(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_errors_per_band = []  # list of [C, N_pixels] tensors\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, _ in dataloader:\n",
    "            batch = batch.unsqueeze(1).to(device)  # [B, 1, C, H, W]\n",
    "            recon = model(batch)                   # [B, 1, C, H, W]\n",
    "            error = (recon - batch).pow(2).squeeze(1)  # [B, C, H, W]\n",
    "\n",
    "            # Reshape to [C, B*H*W]\n",
    "            error_per_band = error.permute(1, 0, 2, 3).reshape(error.shape[1], -1)\n",
    "            all_errors_per_band.append(error_per_band.cpu())\n",
    "\n",
    "    # Concatenate along pixel dimension\n",
    "    all_errors_per_band = torch.cat(all_errors_per_band, dim=1)  # [C, total_pixels]\n",
    "    return all_errors_per_band  # tensor [C, N_pixels_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de42c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Validation\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "\n",
    "all_pixel_errors_per_band = []\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors_per_band = get_pixel_errors_per_band(model, loader, device)\n",
    "    all_pixel_errors_per_band.append(errors_per_band)  # list of [C, N_pixels] tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7228e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = all_pixel_errors_per_band[0].shape[0]\n",
    "\n",
    "for band_idx in range(n_bands):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    band_group_errors = []  # for violin plot\n",
    "    for group_idx, errors_tensor in enumerate(all_pixel_errors_per_band):\n",
    "        # Get errors for this band\n",
    "        band_errors = errors_tensor[band_idx].numpy()\n",
    "        band_group_errors.append(band_errors)\n",
    "\n",
    "    # Optional: Clip extreme values globally for better visualization\n",
    "    lower_bound = 5\n",
    "    upper_bound = 95\n",
    "    lower_clip = np.percentile(np.concatenate(band_group_errors), lower_bound)\n",
    "    upper_clip = np.percentile(np.concatenate(band_group_errors), upper_bound)\n",
    "    \n",
    "    band_group_errors_clipped = [np.clip(errors, lower_clip, upper_clip) for errors in band_group_errors]\n",
    "\n",
    "    # Create violin plot\n",
    "    parts = plt.violinplot(\n",
    "        band_group_errors_clipped,\n",
    "        showmeans=True,\n",
    "        showmedians=True,\n",
    "        showextrema=True\n",
    "    )\n",
    "\n",
    "    # Customize colors\n",
    "    for idx, pc in enumerate(parts['bodies']):\n",
    "        pc.set_facecolor(colors[idx])\n",
    "        pc.set_alpha(0.6)\n",
    "\n",
    "    plt.xticks(\n",
    "        ticks=np.arange(1, len(group_labels) + 1),\n",
    "        labels=group_labels,\n",
    "        rotation=30\n",
    "    )\n",
    "    # Draw threshold once per band\n",
    "    # plt.axhline(y=thresholds[band_idx], color='red', linestyle='--', label=f'Threshold ({thresholds[band_idx]:.2f})')\n",
    "    plt.title(f\"Band {band_idx+1} - Pixelwise Reconstruction Errors by Group\")\n",
    "    plt.ylabel(\"Pixelwise Reconstruction Error\")\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}pixelwise_perimage_violin_band{band_idx+1}_{lower_bound}_{upper_bound}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c340f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error, x_coords, y_coords = visualize_pixel_spectra_combined_3d(\n",
    "    model, \n",
    "    dataloader_early_diseased_hsi, \n",
    "    device, \n",
    "    n_pixels=100,\n",
    "    error_type='mae',\n",
    "    mask_after=True,\n",
    "    remove_edges=True,\n",
    "    mask_resize=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b5781",
   "metadata": {},
   "source": [
    "### Inference into the latent space (UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "672b85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_healthy, labels_healthy, images_healthy = get_lat_representations(model, dataloader_train_hsi, device, assigned_label=0)\n",
    "latent_early, labels_early, images_early = get_lat_representations(model, dataloader_early_diseased_hsi, device, assigned_label=1)\n",
    "#latent_mid, labels_mid, images_mid = get_lat_representations(model, dataloader_mid_diseased_hsi, device, assigned_label=2)\n",
    "latent_late, labels_late, images_late = get_lat_representations(model, dataloader_late_diseased_hsi, device, assigned_label=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_all = np.concatenate([latent_healthy, latent_early, latent_mid, latent_late], axis=0)\n",
    "labels_all = np.concatenate([labels_healthy, labels_early, labels_mid, labels_late], axis=0)\n",
    "images_all = torch.cat([images_healthy, images_early, images_mid, images_late], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_interactive(latent_all, images_all, labels=labels_all, n_neighbors=3, min_dist=0.05) #latent_array, images, labels=None, RGB_bands=[9, 3, 5], image_scale=0.2, click_threshold=1.0, n_neighbors=15, min_dist=0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
