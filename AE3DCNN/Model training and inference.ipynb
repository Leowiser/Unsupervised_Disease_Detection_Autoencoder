{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5feb6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r0979317/miniconda3/envs/env_thesis/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import joblib\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "from datasets import *\n",
    "from CNN_AE_helper import *\n",
    "from CNN3d import *\n",
    "from torchvision.transforms import v2\n",
    "from scipy.ndimage import binary_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f7dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy: 221\n",
      "Early diseased: 12\n",
      "Mid diseased: 25\n",
      "Late diseased: 30\n"
     ]
    }
   ],
   "source": [
    "# FX10 camera\n",
    "#IMG_DIR = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/'\n",
    "IMG_DIR = '/home/u0158953/data/Strawberries/PotsprocessedData/cropped_hdf5'\n",
    "CAMERA = 'FX10'\n",
    "\n",
    "# Healthy leaves\n",
    "DATES = ['07SEPT2023', '08SEPT2023', '09SEPT2023', '10SEPT2023', '11SEPT2023', '12SEPT2023',\n",
    "         '13SEPT2023', '14SEPT2023', '15SEPT2023', '18SEPT2023', '19SEPT2023']\n",
    "TRAYS = ['4C', '4D', '2D']    # Some files from the FX17 camera are mistakenly named in 2D instead of 4D\n",
    "healthy_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Early diseased leaves\n",
    "DATES = ['07SEPT2023']\n",
    "TRAYS = ['3C']\n",
    "early_diseased_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Mid diseased leaves\n",
    "DATES = ['08SEPT2023', '09SEPT2023']\n",
    "TRAYS = ['3C']\n",
    "mid_diseased_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Late diseased leaves\n",
    "DATES = ['10SEPT2023', '11SEPT2023', '12SEPT2023', '13SEPT2023', '14SEPT2023', '15SEPT2023']\n",
    "TRAYS = ['3C']\n",
    "late_diseased_FX10 = filter_filenames(folder_path=IMG_DIR, camera_id=CAMERA, date_stamps=DATES, tray_ids=TRAYS)\n",
    "\n",
    "# Number of samples in each category\n",
    "print(f'Healthy: {len(healthy_FX10)}')\n",
    "print(f'Early diseased: {len(early_diseased_FX10)}')\n",
    "print(f'Mid diseased: {len(mid_diseased_FX10)}')\n",
    "print(f'Late diseased: {len(late_diseased_FX10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ecd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(healthy_FX10, test_size=0.20)\n",
    "train, validation = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36aa1384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Total number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    " # For now these only apply for the HSI data, but eventually we will only need that\n",
    "INPUT_DATA = healthy_FX10[0:10]    # [0:40] just to speed up the process for now\n",
    "MASK_FOLDER = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_masks'\n",
    "# MASK_FOLDER = \"/home/u0158953/data/Strawberries/PotsprocessedData/cropped_masks\"\n",
    "BATCH_SIZE = 8\n",
    "MASK_METHOD = 1    # 0 for only leaf, 1 for leaf+stem\n",
    "BAND_SELECTION = [489.3, 505.1, 542.21, 550.2, 558.21, 582.31, 625.4, 660.62, 674.2, 679.64,\n",
    "                  701.44, 717.81, 736.94, 745.15, 783.52, 849.54, 951.83]    # Important wavelengths obtained from pca_bandselect.ipynb\n",
    "POLYORDER = 2\n",
    "WINDOW_LENGTH = 4 \n",
    "PREPROCESS_METHOD = \"normal\"\n",
    "#SCALER = joblib.load('models/pca/scaler_healthy.joblib')    # Only needed if we want to transform data to PCA space\n",
    "#PCA = joblib.load('models/pca/pca_model_healthy.joblib')    # Only needed if we want to transform data to PCA space\n",
    "device = 'cpu'\n",
    "print(f'Using {device} device')\n",
    "print(f'Total number of GPUs: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001d7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentations\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=(0, 180), interpolation=v2.InterpolationMode.BILINEAR),\n",
    "    v2.Resize((256, 256)),    # By default this uses bilinear interpolation which is good.\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6e78d22",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:41:55 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_13SEPT2023_4D5_3.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create Dataset and DataLoader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_train_hsi \u001b[38;5;241m=\u001b[39m HsiDataset(train, MASK_FOLDER, transform\u001b[38;5;241m=\u001b[39mtrain_transforms, \n\u001b[0;32m      3\u001b[0m                                apply_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_method\u001b[38;5;241m=\u001b[39mMASK_METHOD, min_wavelength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m430\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, selected_bands\u001b[38;5;241m=\u001b[39mBAND_SELECTION, \n\u001b[0;32m      4\u001b[0m                                polyorder\u001b[38;5;241m=\u001b[39mPOLYORDER, window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH, preprocess_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m dataloader_train_hsi \u001b[38;5;241m=\u001b[39m DataLoader(dataset_train_hsi, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mpadded_collate)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\datasets.py:67\u001b[0m, in \u001b[0;36mHsiDataset.__init__\u001b[1;34m(self, img_paths, mask_dir, transform, apply_mask, mask_method, min_wavelength, normalize, selected_bands, polyorder, window_length, deriv, preprocess_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_method \u001b[38;5;241m=\u001b[39m preprocess_method\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load wavelengths from the first image (but could be any image since images have the same spectral bands)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwlens \u001b[38;5;241m=\u001b[39m LoadHSI(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_paths[\u001b[38;5;241m0\u001b[39m], return_wlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\utils.py:10\u001b[0m, in \u001b[0;36mLoadHSI\u001b[1;34m(path_to_hdf5, return_wlens, print_info)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadHSI\u001b[39m(path_to_hdf5, return_wlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# we handle two type, h5 and hdf5\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filetype \u001b[38;5;241m=\u001b[39m path_to_hdf5\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path_to_hdf5, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             hypercube_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHypercube\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:41:55 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_13SEPT2023_4D5_3.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset_train_hsi = HsiDataset(train, MASK_FOLDER, transform=train_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, window_length=WINDOW_LENGTH, preprocess_method = \"normal\")\n",
    "dataloader_train_hsi = DataLoader(dataset_train_hsi, batch_size=BATCH_SIZE, shuffle=True, collate_fn=padded_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81c9af3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:03 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_13SEPT2023_4D5_3.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create Dataset and DataLoader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_train_hsi_normal \u001b[38;5;241m=\u001b[39m HsiDataset(train, MASK_FOLDER, transform\u001b[38;5;241m=\u001b[39mtrain_transforms, \n\u001b[0;32m      3\u001b[0m                                apply_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_method\u001b[38;5;241m=\u001b[39mMASK_METHOD, min_wavelength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m430\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, selected_bands\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m      4\u001b[0m                                polyorder\u001b[38;5;241m=\u001b[39mPOLYORDER, window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH, preprocess_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m dataloader_train_hsi_normal \u001b[38;5;241m=\u001b[39m DataLoader(dataset_train_hsi_normal, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mpadded_collate)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\datasets.py:67\u001b[0m, in \u001b[0;36mHsiDataset.__init__\u001b[1;34m(self, img_paths, mask_dir, transform, apply_mask, mask_method, min_wavelength, normalize, selected_bands, polyorder, window_length, deriv, preprocess_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_method \u001b[38;5;241m=\u001b[39m preprocess_method\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load wavelengths from the first image (but could be any image since images have the same spectral bands)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwlens \u001b[38;5;241m=\u001b[39m LoadHSI(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_paths[\u001b[38;5;241m0\u001b[39m], return_wlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\utils.py:10\u001b[0m, in \u001b[0;36mLoadHSI\u001b[1;34m(path_to_hdf5, return_wlens, print_info)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadHSI\u001b[39m(path_to_hdf5, return_wlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# we handle two type, h5 and hdf5\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filetype \u001b[38;5;241m=\u001b[39m path_to_hdf5\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path_to_hdf5, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             hypercube_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHypercube\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:03 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_13SEPT2023_4D5_3.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset_train_hsi_normal = HsiDataset(train, MASK_FOLDER, transform=train_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=False, selected_bands=None, \n",
    "                               polyorder=POLYORDER, window_length=WINDOW_LENGTH, preprocess_method = \"normal\")\n",
    "dataloader_train_hsi_normal = DataLoader(dataset_train_hsi_normal, batch_size=BATCH_SIZE, shuffle=True, collate_fn=padded_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52277890",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:04 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_13SEPT2023_4D5_3.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create Dataset and DataLoader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_train_hsi_savgol \u001b[38;5;241m=\u001b[39m HsiDataset(train, MASK_FOLDER, transform\u001b[38;5;241m=\u001b[39mtrain_transforms, \n\u001b[0;32m      3\u001b[0m                                apply_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_method\u001b[38;5;241m=\u001b[39mMASK_METHOD, min_wavelength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m430\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, selected_bands\u001b[38;5;241m=\u001b[39mBAND_SELECTION, \n\u001b[0;32m      4\u001b[0m                                polyorder\u001b[38;5;241m=\u001b[39mPOLYORDER, deriv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH, preprocess_method \u001b[38;5;241m=\u001b[39m PREPROCESS_METHOD)\n\u001b[0;32m      5\u001b[0m dataloader_train_hsi_savgol \u001b[38;5;241m=\u001b[39m DataLoader(dataset_train_hsi_savgol, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mpadded_collate)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\datasets.py:67\u001b[0m, in \u001b[0;36mHsiDataset.__init__\u001b[1;34m(self, img_paths, mask_dir, transform, apply_mask, mask_method, min_wavelength, normalize, selected_bands, polyorder, window_length, deriv, preprocess_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_method \u001b[38;5;241m=\u001b[39m preprocess_method\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load wavelengths from the first image (but could be any image since images have the same spectral bands)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwlens \u001b[38;5;241m=\u001b[39m LoadHSI(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_paths[\u001b[38;5;241m0\u001b[39m], return_wlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\utils.py:10\u001b[0m, in \u001b[0;36mLoadHSI\u001b[1;34m(path_to_hdf5, return_wlens, print_info)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadHSI\u001b[39m(path_to_hdf5, return_wlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# we handle two type, h5 and hdf5\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filetype \u001b[38;5;241m=\u001b[39m path_to_hdf5\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path_to_hdf5, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             hypercube_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHypercube\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:04 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_13SEPT2023_4D5_3.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset_train_hsi_savgol = HsiDataset(train, MASK_FOLDER, transform=train_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD)\n",
    "dataloader_train_hsi_savgol = DataLoader(dataset_train_hsi_savgol, batch_size=BATCH_SIZE, shuffle=True, collate_fn=padded_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc07f6ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train_hsi_normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, _ \u001b[38;5;129;01min\u001b[39;00m dataloader_train_hsi_normal:  \u001b[38;5;66;03m# assuming (images, labels)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# data shape: (B, C, H, W)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m     num_to_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m10\u001b[39m, batch_size)  \u001b[38;5;66;03m# in case batch size < 10\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train_hsi_normal' is not defined"
     ]
    }
   ],
   "source": [
    "for data, _ in dataloader_train_hsi_normal:  # assuming (images, labels)\n",
    "    # data shape: (B, C, H, W)\n",
    "    batch_size = data.shape[0]\n",
    "    num_to_plot = min(10, batch_size)  # in case batch size < 10\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i in range(num_to_plot):\n",
    "        image = data[i]  # shape: (C, H, W)\n",
    "\n",
    "        # Convert to numpy\n",
    "        image = image.detach().cpu().numpy()\n",
    "\n",
    "        # Mean spectrum across spatial dims\n",
    "        mean_spectrum = image.mean(axis=(1, 2))\n",
    "\n",
    "        # Plot\n",
    "        plt.plot(mean_spectrum, label=f\"Image {i}\")\n",
    "\n",
    "    plt.xlabel(\"Wavelength Index\")\n",
    "    plt.ylabel(\"Mean Intensity\")\n",
    "    plt.title(\"Mean Spectra of 10 Images\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    break  # only do the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99036911",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:06 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_09SEPT2023_4D2_0.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create Dataset and DataLoader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_validation_hsi \u001b[38;5;241m=\u001b[39m HsiDataset(validation, MASK_FOLDER, transform\u001b[38;5;241m=\u001b[39mtrain_transforms, \n\u001b[0;32m      3\u001b[0m                                apply_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_method\u001b[38;5;241m=\u001b[39mMASK_METHOD, min_wavelength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m430\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, selected_bands\u001b[38;5;241m=\u001b[39mBAND_SELECTION, \n\u001b[0;32m      4\u001b[0m                                polyorder\u001b[38;5;241m=\u001b[39mPOLYORDER, deriv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH, preprocess_method \u001b[38;5;241m=\u001b[39m PREPROCESS_METHOD)\n\u001b[0;32m      5\u001b[0m dataloader_validation_hsi \u001b[38;5;241m=\u001b[39m DataLoader(dataset_validation_hsi, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mpadded_collate)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\datasets.py:67\u001b[0m, in \u001b[0;36mHsiDataset.__init__\u001b[1;34m(self, img_paths, mask_dir, transform, apply_mask, mask_method, min_wavelength, normalize, selected_bands, polyorder, window_length, deriv, preprocess_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_method \u001b[38;5;241m=\u001b[39m preprocess_method\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load wavelengths from the first image (but could be any image since images have the same spectral bands)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwlens \u001b[38;5;241m=\u001b[39m LoadHSI(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_paths[\u001b[38;5;241m0\u001b[39m], return_wlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\utils.py:10\u001b[0m, in \u001b[0;36mLoadHSI\u001b[1;34m(path_to_hdf5, return_wlens, print_info)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadHSI\u001b[39m(path_to_hdf5, return_wlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# we handle two type, h5 and hdf5\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filetype \u001b[38;5;241m=\u001b[39m path_to_hdf5\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path_to_hdf5, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             hypercube_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHypercube\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:06 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_09SEPT2023_4D2_0.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset_validation_hsi = HsiDataset(validation, MASK_FOLDER, transform=train_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD)\n",
    "dataloader_validation_hsi = DataLoader(dataset_validation_hsi, batch_size=BATCH_SIZE, shuffle=True, collate_fn=padded_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39a71950",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:06 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_15SEPT2023_4D4_5.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create Dataset and DataLoader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_test_hsi \u001b[38;5;241m=\u001b[39m HsiDataset(test, MASK_FOLDER, transform\u001b[38;5;241m=\u001b[39mtrain_transforms, \n\u001b[0;32m      3\u001b[0m                                apply_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_method\u001b[38;5;241m=\u001b[39mMASK_METHOD, min_wavelength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m430\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, selected_bands\u001b[38;5;241m=\u001b[39mBAND_SELECTION, \n\u001b[0;32m      4\u001b[0m                                polyorder\u001b[38;5;241m=\u001b[39mPOLYORDER, deriv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH, preprocess_method \u001b[38;5;241m=\u001b[39m PREPROCESS_METHOD)\n\u001b[0;32m      5\u001b[0m dataloader_test_hsi \u001b[38;5;241m=\u001b[39m DataLoader(dataset_test_hsi, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mpadded_collate)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\datasets.py:67\u001b[0m, in \u001b[0;36mHsiDataset.__init__\u001b[1;34m(self, img_paths, mask_dir, transform, apply_mask, mask_method, min_wavelength, normalize, selected_bands, polyorder, window_length, deriv, preprocess_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_method \u001b[38;5;241m=\u001b[39m preprocess_method\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load wavelengths from the first image (but could be any image since images have the same spectral bands)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwlens \u001b[38;5;241m=\u001b[39m LoadHSI(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_paths[\u001b[38;5;241m0\u001b[39m], return_wlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\utils.py:10\u001b[0m, in \u001b[0;36mLoadHSI\u001b[1;34m(path_to_hdf5, return_wlens, print_info)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadHSI\u001b[39m(path_to_hdf5, return_wlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# we handle two type, h5 and hdf5\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filetype \u001b[38;5;241m=\u001b[39m path_to_hdf5\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path_to_hdf5, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             hypercube_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHypercube\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:06 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_15SEPT2023_4D4_5.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset_test_hsi = HsiDataset(test, MASK_FOLDER, transform=train_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD)\n",
    "dataloader_test_hsi = DataLoader(dataset_test_hsi, batch_size=BATCH_SIZE, shuffle=True, collate_fn=padded_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8039fd60",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:07 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_07SEPT2023_3C1_2.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Early diseased\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_early_diseased_hsi \u001b[38;5;241m=\u001b[39m HsiDataset(early_diseased_FX10, MASK_FOLDER, transform\u001b[38;5;241m=\u001b[39mtest_transforms, \n\u001b[0;32m      3\u001b[0m                                apply_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_method\u001b[38;5;241m=\u001b[39mMASK_METHOD, min_wavelength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m430\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, selected_bands\u001b[38;5;241m=\u001b[39mBAND_SELECTION, \n\u001b[0;32m      4\u001b[0m                                polyorder\u001b[38;5;241m=\u001b[39mPOLYORDER, deriv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH, preprocess_method \u001b[38;5;241m=\u001b[39m PREPROCESS_METHOD)\n\u001b[0;32m      5\u001b[0m dataloader_early_diseased_hsi \u001b[38;5;241m=\u001b[39m DataLoader(dataset_early_diseased_hsi, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Mid diseased\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\datasets.py:67\u001b[0m, in \u001b[0;36mHsiDataset.__init__\u001b[1;34m(self, img_paths, mask_dir, transform, apply_mask, mask_method, min_wavelength, normalize, selected_bands, polyorder, window_length, deriv, preprocess_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_method \u001b[38;5;241m=\u001b[39m preprocess_method\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load wavelengths from the first image (but could be any image since images have the same spectral bands)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwlens \u001b[38;5;241m=\u001b[39m LoadHSI(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_paths[\u001b[38;5;241m0\u001b[39m], return_wlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leonw\\OneDrive - KU Leuven\\Master Thesis\\GitLab\\master_thesis\\AE3DCNN\\utils.py:10\u001b[0m, in \u001b[0;36mLoadHSI\u001b[1;34m(path_to_hdf5, return_wlens, print_info)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadHSI\u001b[39m(path_to_hdf5, return_wlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# we handle two type, h5 and hdf5\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filetype \u001b[38;5;241m=\u001b[39m path_to_hdf5\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path_to_hdf5, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             hypercube_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHypercube\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\leonw\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (file read failed: time = Tue Apr 22 12:42:07 2025\n, filename = 'C:/Users/leonw/OneDrive - KU Leuven/Master Thesis/Data_cropped/cropped_hdf5/FX10_07SEPT2023_3C1_2.hdf5', file descriptor = 3, errno = 22, error message = 'Invalid argument', buf = 00000046631EC180, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# Early diseased\n",
    "dataset_early_diseased_hsi = HsiDataset(early_diseased_FX10, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD)\n",
    "dataloader_early_diseased_hsi = DataLoader(dataset_early_diseased_hsi, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Mid diseased\n",
    "dataset_mid_diseased_hsi = HsiDataset(mid_diseased_FX10, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD)\n",
    "dataloader_mid_diseased_hsi = DataLoader(dataset_mid_diseased_hsi, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Late diseased\n",
    "dataset_late_diseased_hsi = HsiDataset(late_diseased_FX10, MASK_FOLDER, transform=test_transforms, \n",
    "                               apply_mask=True, mask_method=MASK_METHOD, min_wavelength=430, normalize=True, selected_bands=BAND_SELECTION, \n",
    "                               polyorder=POLYORDER, deriv = 2, window_length=WINDOW_LENGTH, preprocess_method = PREPROCESS_METHOD)\n",
    "dataloader_late_diseased_hsi = DataLoader(dataset_late_diseased_hsi, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "attn_masks =[]\n",
    "for img in batch:\n",
    "    img = img.numpy() # shape (B, H, W)\n",
    "    # compute spectral std and edges as before\n",
    "    spectral_std = img.std(axis=0)\n",
    "    gray = img.mean(axis=0)\n",
    "    gray_uint8 = (gray/gray.max()*255).astype(np.uint8)\n",
    "    edges = cv2.Canny(gray_uint8, 50, 150).astype(np.float32)\n",
    "    # combine\n",
    "    spectral_std_norm = spectral_std / (spectral_std.max() + 1e-8)\n",
    "    edges_norm = edges / 255.0\n",
    "    attn = spectral_std_norm + edges_norm\n",
    "    attn = attn / (attn.max() + 1e-8)\n",
    "    attn_masks.append(torch.tensor(attn, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e99b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "\n",
    "def compute_hessian_eigenvalues(image, sigma=1.0):\n",
    "    # Gaussian second derivatives\n",
    "    Dxx = gaussian_filter(image, sigma=sigma, order=(2, 0))\n",
    "    Dyy = gaussian_filter(image, sigma=sigma, order=(0, 2))\n",
    "    Dxy = gaussian_filter(image, sigma=sigma, order=(1, 1))\n",
    "\n",
    "    # Eigenvalue computation\n",
    "    trace = Dxx + Dyy\n",
    "    det = Dxx * Dyy - Dxy ** 2\n",
    "    temp = np.sqrt((Dxx - Dyy)**2 + 4 * Dxy**2)\n",
    "    \n",
    "    lambda1 = 0.5 * (Dxx + Dyy + temp)\n",
    "    lambda2 = 0.5 * (Dxx + Dyy - temp)\n",
    "\n",
    "    # Major eigenvalue at each pixel\n",
    "    major = np.maximum(lambda1, lambda2)\n",
    "    return major, lambda1, lambda2\n",
    "\n",
    "# Example usage:\n",
    "# If your hyperspectral image is `hsi` with shape (248, 256, 256):\n",
    "def apply_hessian_to_hsi(hsi_cube, sigma=1.0):\n",
    "    eigen_cube = []\n",
    "    for i in range(hsi_cube.shape[0]):\n",
    "        major, _, _ = compute_hessian_eigenvalues(hsi_cube[i], sigma)\n",
    "        eigen_cube.append(major)\n",
    "    return np.stack(eigen_cube)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "\n",
    "def steger_line_detection(image, sigma=1.0):\n",
    "    # 1. Compute first and second derivatives\n",
    "    Ix = gaussian_filter(image, sigma=sigma, order=(1, 0))\n",
    "    Iy = gaussian_filter(image, sigma=sigma, order=(0, 1))\n",
    "\n",
    "    Ixx = gaussian_filter(image, sigma=sigma, order=(2, 0))\n",
    "    Iyy = gaussian_filter(image, sigma=sigma, order=(0, 2))\n",
    "    Ixy = gaussian_filter(image, sigma=sigma, order=(1, 1))\n",
    "\n",
    "    # 2. Compute eigenvalues and eigenvectors of Hessian matrix\n",
    "    tmp = np.sqrt((Ixx - Iyy) ** 2 + 4 * Ixy ** 2)\n",
    "    lambda1 = 0.5 * (Ixx + Iyy + tmp)\n",
    "    lambda2 = 0.5 * (Ixx + Iyy - tmp)\n",
    "\n",
    "    # 3. Determine the direction of the eigenvector associated with lambda2\n",
    "    vx = 2 * Ixy\n",
    "    vy = Iyy - Ixx + tmp\n",
    "    norm = np.sqrt(vx ** 2 + vy ** 2)\n",
    "    vx /= norm\n",
    "    vy /= norm\n",
    "\n",
    "    # 4. Interpolate to subpixel accuracy (zero-crossing along gradient direction)\n",
    "    t = -(Ix * vx + Iy * vy) / (lambda2 * (vx ** 2 + vy ** 2))\n",
    "    x_subpixel = np.clip(np.arange(image.shape[1])[None, :] + t * vx, 0, image.shape[1] - 1)\n",
    "    y_subpixel = np.clip(np.arange(image.shape[0])[:, None] + t * vy, 0, image.shape[0] - 1)\n",
    "\n",
    "    # 5. Output line strength (absolute lambda2) and subpixel position\n",
    "    line_strength = np.abs(lambda2)\n",
    "    return line_strength, x_subpixel, y_subpixel\n",
    "\n",
    "# Apply across all hyperspectral bands\n",
    "def apply_steger_to_hsi(hsi_cube, sigma=1.0):\n",
    "    strength_stack = []\n",
    "    for i in range(hsi_cube.shape[0]):\n",
    "        strength, _, _ = steger_line_detection(hsi_cube[i], sigma)\n",
    "        strength_stack.append(strength)\n",
    "    return np.stack(strength_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose your image is named hsi_cube\n",
    "import matplotlib.pyplot as plt\n",
    "for img in batch:\n",
    "    img = img.numpy() # shape (B, H, W)\n",
    "    hsi_np = img.astype(np.float32)\n",
    "    # Apply Hessian-based major eigenvalue method\n",
    "    hessian_response = apply_hessian_to_hsi(hsi_np, sigma=1.0)  # shape: (248, 256, 256)\n",
    "\n",
    "    # Apply Steger's method\n",
    "    steger_response = apply_steger_to_hsi(hsi_np, sigma=1.0)  # shape: (248, 256, 256)\n",
    "    ridge_map = np.mean(hessian_response, axis=0)\n",
    "    line_map = np.mean(steger_response, axis=0)\n",
    "    # same plot code as above\n",
    "    norm_ridge_map = minmax_scale(ridge_map.ravel()).reshape(ridge_map.shape)\n",
    "    norm_line_map = minmax_scale(line_map.ravel()).reshape(line_map.shape)\n",
    "    threshold = 0.6  # tune this!\n",
    "    binary_mask = norm_line_map > threshold\n",
    "\n",
    "    rgb = img[[9, 3, 5]]  # Pick bands for RGB\n",
    "    rgb -= rgb.min()\n",
    "    rgb /= rgb.max()\n",
    "    rgb = rgb.transpose(1, 2, 0)  # [H, W, 3]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(\"Input RGB Composite\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(binary_mask, cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Thresholded Line Map\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plot code as above\n",
    "ridge_map = np.mean(hessian_response, axis=0)\n",
    "line_map = np.mean(steger_response, axis=0)\n",
    "# same plot code as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "norm_ridge_map = minmax_scale(ridge_map.ravel()).reshape(ridge_map.shape)\n",
    "norm_line_map = minmax_scale(line_map.ravel()).reshape(line_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.09  # tune this!\n",
    "binary_mask = norm_line_map > threshold\n",
    "\n",
    "plt.imshow(binary_mask, cmap='gray')\n",
    "plt.title(\"Thresholded Line Map\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_path = os.path.join(MASK_FOLDER, os.path.basename(image_path).replace('.hdf5', '.png'))\n",
    "mask = read_mask('/home/u0158953/data/Strawberries/PotsprocessedData/cropped_masks/FX10_10SEPT2023_4D2_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import binary_erosion\n",
    "\n",
    "def extract_edge(mask, edge_width=2):\n",
    "    # Ensure the mask is boolean\n",
    "    mask = mask.astype(bool)\n",
    "    eroded = mask.copy()\n",
    "    \n",
    "    for _ in range(edge_width):\n",
    "        eroded = binary_erosion(eroded)\n",
    "    \n",
    "    # XOR between original and eroded to get edge\n",
    "    edge = np.logical_xor(mask, eroded)\n",
    "    \n",
    "    return edge.astype(np.uint8)  # Optional: return as uint8 for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_line = extract_edge(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31897c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_np = LoadHSI('/home/u0158953/data/Strawberries/PotsprocessedData/cropped_hdf5/FX10_10SEPT2023_4D2_1.hdf5', return_wlens=False)\n",
    "hsi_np = hsi_np * np.where(mask == 2, 1, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = hsi_np[[9, 3, 5]]  # Pick bands for RGB\n",
    "rgb -= rgb.min()\n",
    "rgb /= rgb.max()\n",
    "rgb = rgb.transpose(1, 2, 0)  # [H, W, 3]\n",
    "\n",
    "plt.imshow(edge_line, cmap='gray')\n",
    "plt.title(\"Thresholded Line Map\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"Input RGB Composite\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(edge_line, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title(\"Thresholded Line Map\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Function to compute pixelwise error for an entire dataloader ---\n",
    "def get_reconstruction_errors(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_errors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch,_ in dataloader:\n",
    "            batch = batch.unsqueeze(1).to(device)  # shape: [B, 1, C, H, W]\n",
    "            recon = model(batch)                  # same shape\n",
    "            error = (recon - batch).pow(2).sum(dim=2)  # sum over spectral bands (C)\n",
    "            # result: [B, 1, H, W]\n",
    "            error = error.squeeze(1)  # now [B, H, W]\n",
    "            all_errors.append(error.cpu().flatten())\n",
    "\n",
    "    return torch.cat(all_errors).numpy()\n",
    "\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = CNN3DAEFC(layers_list=[18,32,32,64,64,128], input_dim=1, kernel_sizes=3, strides=(1, 2, 2), paddings=1, z_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Load the checkpoint\n",
    "model, optimizer, train_losses, val_losses, last_epoch = load_checkpoint(model, '/home/r0979317/Documents/Thesis_Strawberries/models/third_fc_model.pth', device, optimizer)\n",
    "# model.load_state_dict(torch.load(\"/home/r0979317/Documents/Thesis_Strawberries/models/third_fc_model.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "device = next(model.parameters()).device\n",
    "print(\"✅ Model loaded and moved to:\", device)\n",
    "\n",
    "print(\"✅ Model loaded and on device:\", device)\n",
    "\n",
    "# --- Datasets to process ---\n",
    "datasets = {\n",
    "    \"Validation\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "\n",
    "# --- Compute and plot separately ---\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_reconstruction_errors(model, loader, device)\n",
    "\n",
    "    # Optional: clip 99th percentile for visualization\n",
    "    upper = np.percentile(errors, 99)\n",
    "\n",
    "    # --- Plot individual histogram ---\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(errors, bins=100, range=(0, upper), color='skyblue', edgecolor='black', density=True)\n",
    "    plt.title(f\"Reconstruction Error Distribution - {name}\")\n",
    "    plt.xlabel(\"Pixelwise Reconstruction Error\")\n",
    "    plt.ylabel(\"Frequency (normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3DAEMAX_try(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_list=[32, 64, 64, 128],\n",
    "        input_dim=1,\n",
    "        kernel_sizes=3,\n",
    "        strides=(1, 2, 2),\n",
    "        paddings=1\n",
    "    ):\n",
    "        super(CNN3DAEMAX_try, self).__init__()\n",
    "        self.layers_list = layers_list\n",
    "\n",
    "        # Encoder\n",
    "        encoder = []\n",
    "        in_channels = input_dim\n",
    "        for out_channels in layers_list:\n",
    "            encoder.append(nn.Conv3d(in_channels, out_channels, kernel_size=kernel_sizes, stride=1, padding=paddings))\n",
    "            encoder.append(nn.MaxPool3d(kernel_sizes, stride=strides))\n",
    "            encoder.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "        self.encoder = nn.Sequential(*encoder)\n",
    "\n",
    "        # Get output shape of encoder\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, input_dim, 17, 256, 256)\n",
    "            dummy_output = self.encoder(dummy_input)\n",
    "            self.feature_shape = dummy_output.shape[1:]  # (C, D, H, W)\n",
    "\n",
    "        # Decoder (reversed)\n",
    "        decoder = []\n",
    "        rev_layers = layers_list[::-1]\n",
    "        in_channels = rev_layers[0]\n",
    "\n",
    "        for out_channels in rev_layers[1:]:\n",
    "            decoder.append(nn.ConvTranspose3d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_sizes,\n",
    "                stride=strides,\n",
    "                padding=paddings,\n",
    "                output_padding=(0, 1, 1)  # helps recover 256 from downsampling\n",
    "            ))\n",
    "            decoder.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Final layer to bring channels back to input_dim (e.g., 1)\n",
    "        decoder.append(nn.ConvTranspose3d(\n",
    "            in_channels,\n",
    "            input_dim,\n",
    "            kernel_size=kernel_sizes,\n",
    "            stride=strides,\n",
    "            padding=paddings,\n",
    "            output_padding=(0, 1, 1)\n",
    "        ))\n",
    "        self.decoder = nn.Sequential(*decoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        out = F.interpolate(out, size=(17, 256, 256), mode=\"trilinear\", align_corners=False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163cca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN3DAE_VarKernels(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_list=[18, 32, 32, 64],\n",
    "        input_dim=1,\n",
    "        strides=(1, 2, 2),\n",
    "        paddings=(0, 1, 1)\n",
    "    ):\n",
    "        super(CNN3DAE_VarKernels, self).__init__()\n",
    "        self.layers_list = layers_list\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "\n",
    "        # Define varying kernel sizes for encoder\n",
    "        self.encoder_kernel_sizes = [(1, 3, 3), (1, 3, 3), (3, 3, 3), (3, 3, 3)]\n",
    "        self.decoder_kernel_sizes = self.encoder_kernel_sizes[::-1]\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.enc_blocks = nn.ModuleList()\n",
    "        in_channels = input_dim\n",
    "        for out_channels, ks in zip(layers_list, self.encoder_kernel_sizes):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=ks, stride=strides, padding=self.paddings),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            self.enc_blocks.append(block)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # --- Decoder ---\n",
    "        rev_layers = layers_list[::-1]\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "        for idx, (in_channels, out_channels, ks) in enumerate(zip(rev_layers, rev_layers[1:], self.decoder_kernel_sizes[1:])):\n",
    "            block = nn.Sequential(\n",
    "                nn.ConvTranspose3d(\n",
    "                    in_channels, out_channels,\n",
    "                    kernel_size=ks, stride=strides,\n",
    "                    padding=self.paddings, output_padding=(0, 1, 1)\n",
    "                ),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            self.dec_blocks.append(block)\n",
    "\n",
    "        # Final output layer\n",
    "        self.final_layer = nn.ConvTranspose3d(\n",
    "            rev_layers[-1], input_dim,\n",
    "            kernel_size=self.decoder_kernel_sizes[-1], stride=strides,\n",
    "            padding=self.paddings, output_padding=(0, 1, 1)\n",
    "        )\n",
    "\n",
    "    def _encode(self, x):\n",
    "        features = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "        return features\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_feats = self._encode(x)\n",
    "        x = enc_feats[-1]\n",
    "\n",
    "        for idx, block in enumerate(self.dec_blocks):\n",
    "            x = block(x)\n",
    "            if idx == len(self.dec_blocks) - 1:  # last decoder block before final layer\n",
    "                x = x + F.interpolate(enc_feats[0], size=x.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "\n",
    "        # Resize to original input shape\n",
    "        x = F.interpolate(x, size=(17, 256, 256), mode='trilinear', align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269873da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3DAE_TightDropout(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_list=[18, 32, 32, 64],\n",
    "        input_dim=1,\n",
    "        strides=(1, 2, 2),\n",
    "        paddings=(0, 1, 1),\n",
    "        dropout_p=0.2\n",
    "    ):\n",
    "        super(CNN3DAE_TightDropout, self).__init__()\n",
    "\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # Kernel sizes per encoder layer\n",
    "        self.encoder_kernel_sizes = [(1, 3, 3), (1, 3, 3), (3, 3, 3), (3, 3, 3)]\n",
    "        self.decoder_kernel_sizes = self.encoder_kernel_sizes[::-1]\n",
    "\n",
    "        # === Encoder ===\n",
    "        self.enc_blocks = nn.ModuleList()\n",
    "        in_channels = input_dim\n",
    "        for out_channels, ks in zip(layers_list, self.encoder_kernel_sizes):\n",
    "            self.enc_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv3d(in_channels, out_channels, kernel_size=ks, stride=strides, padding=paddings),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Extra encoder bottleneck block for tighter latent space\n",
    "        self.bottleneck_encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, in_channels, kernel_size=(3, 3, 3), stride=strides, padding=paddings),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=dropout_p)\n",
    "        )\n",
    "\n",
    "        # === Decoder ===\n",
    "        rev_layers = layers_list[::-1]\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "        for in_ch, out_ch, ks in zip(rev_layers, rev_layers[1:], self.decoder_kernel_sizes[1:]):\n",
    "            self.dec_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(\n",
    "                        in_ch, out_ch,\n",
    "                        kernel_size=ks, stride=strides,\n",
    "                        padding=paddings, output_padding=(0, 1, 1)\n",
    "                    ),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Extra decoder block to match bottleneck layer\n",
    "        self.bottleneck_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(\n",
    "                rev_layers[0], rev_layers[0],\n",
    "                kernel_size=(3, 3, 3), stride=strides,\n",
    "                padding=paddings, output_padding=(0, 1, 1)\n",
    "            ),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Final output layer\n",
    "        self.final_layer = nn.ConvTranspose3d(\n",
    "            rev_layers[-1], input_dim,\n",
    "            kernel_size=self.decoder_kernel_sizes[-1], stride=strides,\n",
    "            padding=paddings, output_padding=(0, 1, 1)\n",
    "        )\n",
    "\n",
    "    def _encode(self, x):\n",
    "        features = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "        x = self.bottleneck_encoder(x)\n",
    "        return features, x\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_feats, x = self._encode(x)\n",
    "        x = self.bottleneck_decoder(x)\n",
    "\n",
    "        for idx, block in enumerate(self.dec_blocks):\n",
    "            x = block(x)\n",
    "            if idx == len(self.dec_blocks) - 1:\n",
    "                # Final skip connection (after full spatial upsampling)\n",
    "                skip = F.interpolate(enc_feats[0], size=x.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "                x = x + skip\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        x = F.interpolate(x, size=(17, 256, 256), mode='trilinear', align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3DAE_Strict(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_list=[18, 32, 32, 64],\n",
    "        input_dim=1,\n",
    "        strides=(1, 2, 2),\n",
    "        paddings=(0, 1, 1),\n",
    "        dropout_p=0.2\n",
    "    ):\n",
    "        super(CNN3DAE_Strict, self).__init__()\n",
    "\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # Kernel sizes per encoder layer\n",
    "        self.encoder_kernel_sizes = [(1, 3, 3), (1, 3, 3), (3, 3, 3), (3, 3, 3)]\n",
    "        self.decoder_kernel_sizes = self.encoder_kernel_sizes[::-1]\n",
    "\n",
    "        # === Encoder ===\n",
    "        self.enc_blocks = nn.ModuleList()\n",
    "        in_channels = input_dim\n",
    "        for out_channels, ks in zip(layers_list, self.encoder_kernel_sizes):\n",
    "            self.enc_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv3d(in_channels, out_channels, kernel_size=ks, stride=strides, padding=paddings),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Extra encoder bottleneck block for tighter latent space\n",
    "        self.bottleneck_encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, in_channels, kernel_size=(3, 3, 3), stride=strides, padding=paddings),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=dropout_p),\n",
    "            nn.Conv3d(in_channels, in_channels, kernel_size=(3, 3, 3), stride=strides, padding=paddings),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=dropout_p)\n",
    "        )\n",
    "\n",
    "        # === Decoder ===\n",
    "        rev_layers = layers_list[::-1]\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "        for in_ch, out_ch, ks in zip(rev_layers, rev_layers[1:], self.decoder_kernel_sizes[1:]):\n",
    "            self.dec_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(\n",
    "                        in_ch, out_ch,\n",
    "                        kernel_size=ks, stride=strides,\n",
    "                        padding=paddings, output_padding=(0, 1, 1)\n",
    "                    ),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Extra decoder block to match bottleneck layer\n",
    "        self.bottleneck_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(\n",
    "                rev_layers[0], rev_layers[0],\n",
    "                kernel_size=(3, 3, 3), stride=strides,\n",
    "                padding=paddings, output_padding=(0, 1, 1)\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(\n",
    "                rev_layers[0], rev_layers[0],\n",
    "                kernel_size=(3, 3, 3), stride=strides,\n",
    "                padding=paddings, output_padding=(0, 1, 1)\n",
    "            ),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Final output layer\n",
    "        self.final_layer = nn.ConvTranspose3d(\n",
    "            rev_layers[-1], input_dim,\n",
    "            kernel_size=self.decoder_kernel_sizes[-1], stride=strides,\n",
    "            padding=paddings, output_padding=(0, 1, 1)\n",
    "        )\n",
    "\n",
    "    def _encode(self, x):\n",
    "        features = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "        x = self.bottleneck_encoder(x)\n",
    "        return features, x\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_feats, x = self._encode(x)\n",
    "        x = self.bottleneck_decoder(x)\n",
    "\n",
    "        for idx, block in enumerate(self.dec_blocks):\n",
    "            x = block(x)\n",
    "            if idx == len(self.dec_blocks) - 1:\n",
    "                # Final skip connection (after full spatial upsampling)\n",
    "                skip = F.interpolate(enc_feats[0], size=x.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "                x = x + skip\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        x = F.interpolate(x, size=(17, 256, 256), mode='trilinear', align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad548f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ssim\n",
    "\n",
    "def hybrid_loss(output, target, alpha=0.8, beta=0.01):\n",
    "    mse = F.mse_loss(output, target)\n",
    "    ssim_loss = 1 - ssim(output, target, data_range=1.0, size_average=True)\n",
    "\n",
    "    # Optional spectral smoothness regularization\n",
    "    spectral_diff = (output[:, :, 1:, :, :] - output[:, :, :-1, :, :]) ** 2\n",
    "    spectral_smooth = spectral_diff.mean()\n",
    "\n",
    "    return alpha * mse + (1 - alpha) * ssim_loss + beta * spectral_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0803fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now instantiate the model and the trainer\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed_all(10)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Loss function ---\n",
    "def hybrid_loss(output, target, alpha=0.8, beta=0.01):\n",
    "    mse = nn.functional.mse_loss(output, target)\n",
    "    ssim_loss = 1 - ssim(output, target, data_range=1.0, size_average=True)\n",
    "\n",
    "    # Optional spectral smoothness penalty\n",
    "    spectral_diff = (output[:, :, 1:, :, :] - output[:, :, :-1, :, :]) ** 2\n",
    "    spectral_smooth = spectral_diff.mean()\n",
    "\n",
    "    return alpha * mse + (1 - alpha) * ssim_loss + beta * spectral_smooth\n",
    "\n",
    "# --- Instantiate model ---\n",
    "model = CNN3DAE_Strict(\n",
    "    layers_list=[18, 32, 64, 64],\n",
    "    input_dim=1,\n",
    "    strides=(1, 2, 2),\n",
    "    paddings=(0, 1, 1)\n",
    ").to(device)\n",
    "\n",
    "# --- Optimizer ---\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# --- Train ---\n",
    "train_losses, val_losses = train_autoencoder(\n",
    "    200,\n",
    "    model,\n",
    "    dataloader_train_hsi,\n",
    "    device,\n",
    "    dataloader_validation_hsi,\n",
    "    criterion=hybrid_loss,\n",
    "    optimizer=optimizer,\n",
    "    save_model=True,\n",
    "    save_path='/home/r0979317/Documents/Thesis_Strawberries/models/first_strict_model.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture and optimizer again\n",
    "model = CNN3DAE_TightDropout(\n",
    "        layers_list=[18, 32, 64, 64],\n",
    "        input_dim=1,\n",
    "        strides=(1, 2, 2),\n",
    "        paddings=(0, 1, 1)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Load the checkpoint\n",
    "model, optimizer, train_losses, val_losses, last_epoch = load_checkpoint(model, '/home/r0979317/Documents/Thesis_Strawberries/models/first_dropout_model.pth', device, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f701bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, indices in dataloader_validation_hsi:\n",
    "        images = images.unsqueeze(1)\n",
    "        outputs = model(images)\n",
    "        recon_error = torch.abs(images - outputs)\n",
    "        print(recon_error.shape)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            print(idx)\n",
    "            edge_mask = dataset_validation_hsi.get_edge_mask(idx).float()  # (H, W)\n",
    "            print(i)\n",
    "            print(images[idx].shape)\n",
    "            print(edge_mask.shape)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffeb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, indices in dataloader_validation_hsi:\n",
    "        images = images.unsqueeze(1)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        recon_error = torch.abs(images - outputs)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            print(idx)\n",
    "            edge_mask = dataset_validation_hsi.get_edge_mask(idx).float()  # (H, W)\n",
    "            image = images[i]\n",
    "            image = image.squeeze(0)\n",
    "            print(image.shape)\n",
    "            image_slice = image * np.where(edge_mask == 2, 1, edge_mask)\n",
    "\n",
    "            rgb = image[[9, 3, 5]].numpy()  # Pick bands for RGB\n",
    "            rgb -= rgb.min()\n",
    "            rgb /= rgb.max()\n",
    "            rgb = rgb.transpose(1, 2, 0)  # [H, W, 3]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(rgb)\n",
    "            plt.title(\"Input RGB Composite\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(edge_mask, cmap='hot')\n",
    "            plt.colorbar()\n",
    "            plt.title(\"Thresholded Line Map\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()   \n",
    "\n",
    "            break\n",
    "        break \n",
    "            \n",
    "            #H, W = recon_error.shape[2], recon_error.shape[3]\n",
    "\n",
    "'''\n",
    "            # Pad to match shape\n",
    "            pad_height = H - edge_mask.shape[0]\n",
    "            pad_width = W - edge_mask.shape[1]\n",
    "            edge_mask = transforms.functional.pad(edge_mask, (0, pad_width, 0, pad_height))  # (W, H)\n",
    "\n",
    "            # Expand to (C, H, W)\n",
    "            edge_mask = edge_mask.unsqueeze(0).expand(recon_error.shape[1], -1, -1)\n",
    "\n",
    "            # Masked reconstruction error\n",
    "            edge_error = recon_error[i] * edge_mask  # (C, H, W)\n",
    "            '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702115b3",
   "metadata": {},
   "source": [
    "## Inference into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, 199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75660c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed_all(10)\n",
    "threshold = get_recon_error_threshold(model, dataloader_test_hsi, dataloader_early=dataloader_early_diseased_hsi,\n",
    "                                      dataloader_mid=dataloader_mid_diseased_hsi, dataloader_late=dataloader_late_diseased_hsi, device=device)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34970d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to compute pixelwise error for an entire dataloader ---\n",
    "def get_reconstruction_errors(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_errors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch,_ in dataloader:\n",
    "            batch = batch.unsqueeze(1).to(device)  # shape: [B, 1, C, H, W]\n",
    "            recon = model(batch)                  # same shape\n",
    "            error = (recon - batch).pow(2).sum(dim=2)  # sum over spectral bands (C)\n",
    "            # result: [B, 1, H, W]\n",
    "            error = error.squeeze(1)  # now [B, H, W]\n",
    "            all_errors.append(error.cpu().flatten())\n",
    "\n",
    "    return torch.cat(all_errors).numpy()\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/r0979317/Documents/Thesis_Strawberries/models/third_fc_model.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "device = next(model.parameters()).device\n",
    "print(\"✅ Model loaded and moved to:\", device)\n",
    "\n",
    "print(\"✅ Model loaded and on device:\", device)\n",
    "\n",
    "# --- Datasets to process ---\n",
    "datasets = {\n",
    "    \"Validation\": dataloader_validation_hsi,\n",
    "    \"Early Diseased\": dataloader_early_diseased_hsi,\n",
    "    \"Mid Diseased\": dataloader_mid_diseased_hsi,\n",
    "    \"Late Diseased\": dataloader_late_diseased_hsi,\n",
    "}\n",
    "\n",
    "# --- Compute and plot separately ---\n",
    "for name, loader in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    errors = get_reconstruction_errors(model, loader, device)\n",
    "\n",
    "    # Optional: clip 99th percentile for visualization\n",
    "    upper = np.percentile(errors, 99)\n",
    "\n",
    "    # --- Plot individual histogram ---\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(errors, bins=100, range=(0, upper), color='skyblue', edgecolor='black', density=True)\n",
    "    plt.title(f\"Reconstruction Error Distribution - {name}\")\n",
    "    plt.xlabel(\"Pixelwise Reconstruction Error\")\n",
    "    plt.ylabel(\"Frequency (normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to compute pixelwise error for an entire dataloader ---\n",
    "def get_pixel_reconstruction_errors(model, dataloader, device, quantile = 0.75):\n",
    "    model.eval()\n",
    "    all_errors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch,_ in dataloader:\n",
    "            batch = batch.unsqueeze(1).to(device)  # shape: [B, 1, C, H, W]\n",
    "            recon = model(batch)                  # same shape\n",
    "            error = (recon - batch).pow(2).sum(dim=2)  # sum over spectral bands (C)\n",
    "            \n",
    "            all_errors.append(error.cpu().flatten())\n",
    "    all_pixel_errors = torch.cat(all_errors).numpy()\n",
    "    threshold = np.quantile(all_pixel_errors, quantile)\n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24020fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_leaves(model, dataloader, device, threshold):\n",
    "    model.eval()\n",
    "    image_scores =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch,_ in dataloader:\n",
    "            batch = batch.unsqueeze(1).to(device)  # shape: [B, 1, C, H, W]\n",
    "            recon = model(batch) \n",
    "            pixel_errors = (recon-batch).pow(2).squeeze(1).sum(dim=1)\n",
    "\n",
    "            for err_map in pixel_errors:\n",
    "               high_error_pixels = err_map[err_map>threshold]\n",
    "               score = high_error_pixels.sum().mean()\n",
    "               image_scores.append(score)\n",
    "\n",
    "    return image_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1742852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_leaves_mean(model, dataloader, device, threshold):\n",
    "    model.eval()\n",
    "    image_scores =[]\n",
    "    with torch.no_grad():\n",
    "            for batch, _ in dataloader:\n",
    "                batch = batch.unsqueeze(1).to(device)  # [B, 1, D, H, W]\n",
    "                recon = model(batch)\n",
    "                pixel_errors = (recon - batch).pow(2).squeeze(1).sum(dim=1)  # [B, H, W]\n",
    "\n",
    "                for err_map in pixel_errors:\n",
    "                    mean_error = err_map.mean().item()\n",
    "                    image_scores.append(mean_error)\n",
    "    return image_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced12a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_error = get_pixel_reconstruction_errors(model, dataloader_test_hsi, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2764a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_early = classify_leaves(model, dataloader_early_diseased_hsi, device, pix_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd342d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_list = [dataloader_test_hsi, dataloader_early_diseased_hsi, dataloader_mid_diseased_hsi, dataloader_late_diseased_hsi]\n",
    "errors = [] \n",
    "for i in dataloader_list:\n",
    "    errors.append(classify_leaves_mean(model, i, device, pix_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb12c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b73411",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(errors[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "labels = ['Healthy', 'Early Diseased','Mid Diseased', 'Severely Diseased']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (scores, color, label) in enumerate(zip(errors, colors, labels)):\n",
    "    x = [i] * len(scores)\n",
    "    plt.scatter(x, scores, color=color, label=label, alpha=0.7)\n",
    "\n",
    "plt.xticks(ticks=range(len(labels)), labels=labels)\n",
    "plt.ylabel(\"Aggregated Error (Above Threshold)\")\n",
    "plt.title(\"Per-image Error Scores by Group\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40188c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch,_ in dataloader_early_diseased_hsi:\n",
    "    print(batch.shape)\n",
    "    for img in batch:\n",
    "        print(img.shape)\n",
    "        img = img.unsqueeze(0).unsqueeze(0).to(device)\n",
    "        recon = model(img)\n",
    "        error = (recon-img).pow(2).sum(dim=2)\n",
    "        print(error.shape)\n",
    "        compar = error[error>threshold_pixel].sum()/len(error[error>threshold_pixel])\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ad093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction_error(model, dataloader, select_img = 0, device=device):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Get a single batch from validation set\n",
    "    with torch.no_grad():\n",
    "        for data,_ in dataloader:\n",
    "            data = data.unsqueeze(1).to(device)\n",
    "            recon = model(data)  # Forward pass\n",
    "            break  # Take only one batch\n",
    "\n",
    "    # Select one sample from the batch (the first image)\n",
    "    original = data[select_img,0].cpu().numpy()  # Shape: (C, H, W)\n",
    "    reconstructed = recon[select_img,0].cpu().numpy()  # Shape: (C, H, W)\n",
    "\n",
    "    # Compute reconstruction error per pixel (absolute difference)\n",
    "    error_map = np.abs(original - reconstructed)  # Shape: (C, H, W) TODO: At other times we use squared error+mean, which should we use?\n",
    "\n",
    "    # Aggregate error across spectral bands (e.g., sum error across channels)\n",
    "    error_map_aggregated = np.average(error_map, axis=0)  # Shape: (H, W)\n",
    "\n",
    "    RGB_bands = [9, 3, 5]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original[RGB_bands,:,].transpose(1, 2, 0))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(reconstructed[RGB_bands,:,].transpose(1, 2, 0))\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(error_map_aggregated, cmap='hot')\n",
    "    plt.title(\"Reconstruction Error Map\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstruction_error(model, dataloader_validation_hsi, 2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import umap.umap_ as UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_rgb_image(img, RGB_bands=[9, 3, 5]):\n",
    "    \"\"\"\n",
    "    Extracts pseudo-RGB image from a hyperspectral image tensor.\n",
    "    \n",
    "    Parameters:\n",
    "        img (torch.Tensor): Hyperspectral image tensor with shape (C, H, W).\n",
    "        RGB_bands (list): Band indices to use for R, G, and B.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Pseudo-RGB image (H, W, 3) with values normalized between 0 and 1.\n",
    "    \"\"\"\n",
    "    # Extract the bands and convert to numpy array\n",
    "    img_rgb = img[RGB_bands].cpu().numpy()  # shape: (3, H, W)\n",
    "    img_rgb = img_rgb.transpose(1, 2, 0)       # shape: (H, W, 3)\n",
    "    # Normalize for display\n",
    "    img_rgb = (img_rgb - img_rgb.min()) / (img_rgb.max() - img_rgb.min() + 1e-6)\n",
    "    return img_rgb\n",
    "\n",
    "def plot_umap_interactive(latent_array, images, labels=None, RGB_bands=[9, 3, 5], image_scale=0.2, click_threshold=1.0, n_neighbors=15, min_dist=0.1):\n",
    "    \"\"\"\n",
    "    Applies UMAP on latent representations and creates an interactive plot.\n",
    "    Clicking on a point toggles display of its corresponding pseudo-RGB image.\n",
    "\n",
    "    Parameters:\n",
    "        latent_array (np.ndarray): Latent vectors (num_samples x latent_dim)\n",
    "        images (torch.Tensor): Hyperspectral images (num_samples x C x H x W)\n",
    "        labels (np.ndarray or None): Optional labels for coloring\n",
    "        RGB_bands (list): Indices of hyperspectral bands used as R, G, B\n",
    "        image_scale (float): Zoom level of the image thumbnails\n",
    "        click_threshold (float): Max distance to register a click on a point\n",
    "        n_neighbors (int): UMAP parameter for local structure\n",
    "        min_dist (float): UMAP parameter for cluster spread\n",
    "    \"\"\"\n",
    "    reducer = UMAP.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)\n",
    "    umap_result = reducer.fit_transform(latent_array)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    scatter = ax.scatter(umap_result[:, 0], umap_result[:, 1], c=labels if labels is not None else 'blue', cmap='viridis', s=50)\n",
    "    if labels is not None:\n",
    "        plt.colorbar(scatter, label=\"Label\")\n",
    "\n",
    "    ax.set_title(\"Interactive UMAP: Click a point to toggle image\")\n",
    "    ax.set_xlabel(\"UMAP Dimension 1\")\n",
    "    ax.set_ylabel(\"UMAP Dimension 2\")\n",
    "\n",
    "    # Dictionary to hold the currently displayed annotation boxes.\n",
    "    displayed_annotations = {}\n",
    "\n",
    "    def on_click(event):\n",
    "\t# Only consider clicks inside the axes\n",
    "        if event.inaxes != ax:\n",
    "            return\n",
    "\n",
    "\t# Get click coordinates in data space\n",
    "        x_click, y_click = event.xdata, event.ydata\n",
    "\t\n",
    "\t# Compute distances from the click to each point\n",
    "        distances = np.sqrt((umap_result[:, 0] - x_click)**2 + (umap_result[:, 1] - y_click)**2)\n",
    "        closest_idx = np.argmin(distances)\n",
    "\n",
    "\t# Only consider the click if it's close enough to a point\n",
    "        if distances[closest_idx] > click_threshold:\n",
    "            return\n",
    "\n",
    "        # Toggle the image annotation for the closest point\n",
    "        if closest_idx in displayed_annotations:\n",
    "            # Remove the annotation if already displayed\n",
    "            displayed_annotations[closest_idx].remove()\n",
    "            del displayed_annotations[closest_idx]\n",
    "        else:\n",
    "            # Create an annotation box with the pseudo-RGB image\n",
    "            img_rgb = get_pseudo_rgb_image(images[closest_idx], RGB_bands=RGB_bands)\n",
    "            imagebox = OffsetImage(img_rgb, zoom=image_scale)\n",
    "            ab = AnnotationBbox(imagebox, (umap_result[closest_idx, 0], umap_result[closest_idx, 1]),\n",
    "                                frameon=False)\n",
    "            displayed_annotations[closest_idx] = ab\n",
    "            ax.add_artist(ab)\n",
    "\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    # Connect the click event handler\n",
    "    fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_representations(model, dataloader, device, assigned_label=None):\n",
    "    \"\"\"\n",
    "    Passes images through the encoder and collects latent representations, labels, and original images.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained autoencoder model.\n",
    "        dataloader (torch.utils.data.DataLoader): Dataloader for the dataset.\n",
    "        device (torch.device): Device to run the model on.\n",
    "        assigned_label (int, optional): Label to assign to all samples in this dataloader.\n",
    "\n",
    "    Returns:\n",
    "        latent_array (np.ndarray): Array of latent representations (num_samples x latent_dim).\n",
    "        labels_array (np.ndarray): Array of labels for each sample.\n",
    "        all_images (torch.Tensor): Original image tensors.\n",
    "    \"\"\"\n",
    "    model.to(device).eval()\n",
    "    latent_list = []\n",
    "    labels_list = []\n",
    "    image_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch.to(device)\n",
    "            images = images.unsqueeze(1)  # [B, 1, C, H, W]\n",
    "            latent = model.encoder(images)\n",
    "            latent = latent.view(latent.size(0), -1)  # Flatten latent representation\n",
    "\n",
    "            latent_list.append(latent.cpu().numpy())\n",
    "            image_list.append(images.cpu())\n",
    "\n",
    "            if assigned_label is not None:\n",
    "                labels_list.extend([assigned_label] * images.size(0))\n",
    "\n",
    "    latent_array = np.concatenate(latent_list, axis=0)\n",
    "    labels_array = np.array(labels_list) if labels_list else None\n",
    "    all_images = torch.cat(image_list, dim=0)\n",
    "\n",
    "    return latent_array, labels_array, all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_healthy, labels_healthy, images_healthy = get_latent_representations(model, dataloader_train_hsi, device, assigned_label=0)\n",
    "latent_early, labels_early, images_early = get_latent_representations(model, dataloader_early_diseased_hsi, device, assigned_label=1)\n",
    "latent_mid, labels_mid, images_mid = get_latent_representations(model, dataloader_mid_diseased_hsi, device, assigned_label=2)\n",
    "latent_late, labels_late, images_late = get_latent_representations(model, dataloader_late_diseased_hsi, device, assigned_label=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_all = np.concatenate([latent_healthy, latent_early, latent_mid, latent_late], axis=0)\n",
    "labels_all = np.concatenate([labels_healthy, labels_early, labels_mid, labels_late], axis=0)\n",
    "images_all = torch.cat([images_healthy, images_early, images_mid, images_late], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_interactive(latent_all, images_all, labels=labels_all, n_neighbors=3, min_dist=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827043c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture and optimizer again\n",
    "model = CNN3DAE(layers_list=[32,64,128], input_dim=1, kernel_sizes=3, strides=(1, 2, 2), paddings=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Load the checkpoint\n",
    "model, optimizer, train_losses, val_losses, last_epoch = load_checkpoint(model, '/home/r0979317/Documents/Thesis_Strawberries/models/first_model.pth', device, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf62fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstruction_error(model, dataloader_validation_hsi, 2, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_thesis)",
   "language": "python",
   "name": "env_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
